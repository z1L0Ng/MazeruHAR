{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on googlecolab \n",
    "# !pip install hickle\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd drive/MyDrive/PerCom2021-FL-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 22:34:05.700091: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-01 22:34:05.734074: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-01 22:34:05.734098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-01 22:34:05.734910: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-01 22:34:05.740858: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-01 22:34:06.426901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import hickle as hkl \n",
    "import requests \n",
    "import urllib.request\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n",
    "import resampy\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fomating data to adjust for dataset sensor errors\n",
    "def formatData(data,dim):\n",
    "    remainders = data.shape[0]%dim\n",
    "    max_index = data.shape[0] - remainders\n",
    "    data = data[:max_index,:]\n",
    "    new = np.reshape(data, (-1, 128,3))\n",
    "    return new\n",
    "\n",
    "# segment data into windows\n",
    "def segmentData(accData,time_step,step):\n",
    "#     print(accData.shape)\n",
    "    segmentAccData = list()\n",
    "    for i in range(0, accData.shape[0] - time_step,step):\n",
    "        segmentAccData.append(accData[i:i+time_step,:])\n",
    "    return np.asarray(segmentAccData)\n",
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=0,usecols=[2,3,4])\n",
    "    return dataframe.values\n",
    " \n",
    "# load a list of files, such as x, y, z data for a given variable\n",
    "def load_group(filenames, filepath='',trainOrEval=0):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(filepath + name)\n",
    "        data = np.asarray(data)\n",
    "#         print(data.shape)\n",
    "#         data = segmentData(data,128,64)\n",
    "        data = np.asarray(data)\n",
    "        loaded.append(data)\n",
    "    return loaded\n",
    "\n",
    "# check if file exist\n",
    "def isReadableFile(file_path, file_name,flag):\n",
    "    full_path = file_path + \"/\" + file_name\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            return False\n",
    "        elif not os.path.isfile(full_path):\n",
    "            return False\n",
    "        elif not os.access(full_path, os.R_OK):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    except IOError as ex:\n",
    "        print (\"I/O error({0}): {1}\".format(ex.errno, ex.strerror))\n",
    "    except Error as ex:\n",
    "        print (\"Error({0}): {1}\".format(ex.errno, ex.strerror))\n",
    "    return False\n",
    "\n",
    "\n",
    "# stairs down 0 \n",
    "# stairs Up   1\n",
    "# jumping     2\n",
    "# lying       3\n",
    "# standing    4 \n",
    "# sitting     5\n",
    "# running/jogging 6\n",
    "# Walking     7\n",
    "\n",
    "# load a dataset group\n",
    "def load_dataset(group, datasetName='',activity='',orientation='',trainOrEval=0,client = 0):\n",
    "    filepath = 'dataset/'+datasetName +'/'+ group + '/'\n",
    "    filenames = list()\n",
    "    if(isReadableFile('dataset/'+datasetName +'/'+ group, str(client)+'/'+group+'_'+activity+'_'+orientation+'.csv',0)):\n",
    "        filenames += [str(client)+'/'+group+'_'+activity+'_'+orientation+'.csv']\n",
    "    if(isReadableFile('dataset/'+datasetName +'/'+ group, str(client)+'/'+group+'_'+activity+'_2_'+orientation+'.csv',1)):\n",
    "        filenames += [str(client)+'/'+group+'_'+activity+'_2_'+orientation+'.csv']\n",
    "    if(isReadableFile('dataset/'+datasetName +'/'+ group, str(client)+'/'+group+'_'+activity+'_3_'+orientation+'.csv',1)):\n",
    "        filenames += [str(client)+'/'+group+'_'+activity+'_3_'+orientation+'.csv']\n",
    "    X = load_group(filenames, filepath,trainOrEval)\n",
    "    return X\n",
    "\n",
    "# download function for datasets\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definign activities and orientations of REALWORLD dataset\n",
    "activities = ['climbingdown','climbingup','jumping','lying','running','sitting','standing','walking'] \n",
    "# activities = ['standing','sitting','walking','climbingup','climbingdown'] \n",
    "\n",
    "orientations = ['chest','forearm','head','shin','thigh','upperarm','waist']\n",
    "# orientations = ['waist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientationKeyMap = dict() \n",
    "for index,value in enumerate(orientations):\n",
    "    orientationKeyMap[value] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading...\n",
      "dataset already downloaded\n",
      "Data already extracted in /files1/Zilong/Light_Transformer_HAR/datasets/dataset/realworld2016_dataset\n"
     ]
    }
   ],
   "source": [
    "# download and unzipping dataset\n",
    "os.makedirs('dataset',exist_ok=True)\n",
    "print(\"downloading...\")            \n",
    "data_directory = os.path.abspath(\"dataset/realworld2016_dataset.zip\")\n",
    "if not os.path.exists(data_directory):\n",
    "    download_url(\"http://wifo5-14.informatik.uni-mannheim.de/sensor/dataset/realworld2016/realworld2016_dataset.zip\",data_directory)\n",
    "    print(\"download done\")\n",
    "else:\n",
    "    print(\"dataset already downloaded\")\n",
    "    \n",
    "data_directory2 = os.path.abspath(\"dataset/realworld2016_dataset\")\n",
    "if not os.path.exists(data_directory2): \n",
    "    print(\"extracting data\")\n",
    "    with zipfile.ZipFile(data_directory, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.abspath(data_directory2))\n",
    "    print(\"data extracted in \" + data_directory2)\n",
    "else:\n",
    "    print(\"Data already extracted in \" + data_directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unzipping REALWORLD dataset\n",
    "for id in range(1,16):\n",
    "    id = str(id)\n",
    "    for activity in activities:\n",
    "        for sensor in [\"acc\",\"gyr\"]:\n",
    "            dirName = sensor\n",
    "            if(sensor == \"gyr\"):\n",
    "                dirName = \"Gyroscope\"\n",
    "            with zipfile.ZipFile('dataset/realworld2016_dataset/proband'+id+'/data/'+sensor+'_'+str(activity)+'_csv.zip', 'r') as zip_ref:\n",
    "                os.makedirs('dataset/REALWORLD/'+dirName+'/'+id, exist_ok=True)\n",
    "                zip_ref.extractall('dataset/REALWORLD/'+dirName+'/'+id)\n",
    "\n",
    "            for i in range (1,4):\n",
    "                if os.path.exists('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_'+str(i)+'_csv.zip'):\n",
    "                    with zipfile.ZipFile('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_'+str(i)+'_csv.zip', 'r') as zip_ref:\n",
    "                        zip_ref.extractall('dataset/REALWORLD/'+dirName+'/'+id)\n",
    "                    os.remove('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_'+str(i)+'_csv.zip') \n",
    "            if os.path.exists('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_csv.zip'):\n",
    "                with zipfile.ZipFile('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_csv.zip', 'r') as zip_ref:\n",
    "                    zip_ref.extractall('dataset/REALWORLD/'+dirName+'/'+id)\n",
    "                os.remove('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_csv.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downSampleLowPass(toDownSampleData,factor):\n",
    "    accX = signal.decimate(toDownSampleData[:,0],factor)\n",
    "    accY = signal.decimate(toDownSampleData[:,1],factor)\n",
    "    accZ = signal.decimate(toDownSampleData[:,2],factor)\n",
    "    return np.dstack((accX,accY,accZ)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Number 1 Activity : climbingup Orientation :chest\n",
      "Disalignment of:90903 found\n",
      "Acc data: 32863\n",
      "Gyro data: 123766\n",
      "Client Number 2 Activity : jumping Orientation :chest\n",
      "Disalignment of:12938 found\n",
      "Acc data: 4756\n",
      "Gyro data: 17694\n",
      "Client Number 2 Activity : lying Orientation :chest\n",
      "Disalignment of:66040 found\n",
      "Acc data: 31050\n",
      "Gyro data: 97090\n",
      "Client Number 2 Activity : running Orientation :chest\n",
      "Disalignment of:18983 found\n",
      "Acc data: 30655\n",
      "Gyro data: 49638\n",
      "Client Number 2 Activity : standing Orientation :chest\n",
      "Disalignment of:52189 found\n",
      "Acc data: 30769\n",
      "Gyro data: 82958\n",
      "Client Number 4 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:27708 found\n",
      "Acc data: 11089\n",
      "Gyro data: 38797\n",
      "Client Number 4 Activity : climbingup Orientation :chest\n",
      "Disalignment of:20402 found\n",
      "Acc data: 11676\n",
      "Gyro data: 32078\n",
      "Client Number 4 Activity : running Orientation :chest\n",
      "Disalignment of:139657 found\n",
      "Acc data: 52180\n",
      "Gyro data: 191837\n",
      "Client Number 6 Activity : climbingup Orientation :chest\n",
      "Disalignment of:70838 found\n",
      "Acc data: 25950\n",
      "Gyro data: 96788\n",
      "Client Number 7 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:19811 found\n",
      "Acc data: 9671\n",
      "Gyro data: 29482\n",
      "Client Number 7 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:20389 found\n",
      "Acc data: 10042\n",
      "Gyro data: 30431\n",
      "Client Number 7 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:18327 found\n",
      "Acc data: 9172\n",
      "Gyro data: 27499\n",
      "Client Number 7 Activity : climbingup Orientation :chest\n",
      "Disalignment of:29877 found\n",
      "Acc data: 11254\n",
      "Gyro data: 41131\n",
      "Client Number 7 Activity : climbingup Orientation :chest\n",
      "Disalignment of:19398 found\n",
      "Acc data: 10490\n",
      "Gyro data: 29888\n",
      "Client Number 7 Activity : climbingup Orientation :chest\n",
      "Disalignment of:11908 found\n",
      "Acc data: 10250\n",
      "Gyro data: 22158\n",
      "Client Number 7 Activity : walking Orientation :chest\n",
      "Disalignment of:82463 found\n",
      "Acc data: 30905\n",
      "Gyro data: 113368\n",
      "Client Number 8 Activity : climbingup Orientation :chest\n",
      "Disalignment of:120501 found\n",
      "Acc data: 57853\n",
      "Gyro data: 178354\n",
      "Client Number 8 Activity : lying Orientation :chest\n",
      "Disalignment of:27685 found\n",
      "Acc data: 31654\n",
      "Gyro data: 59339\n",
      "Client Number 9 Activity : climbingup Orientation :chest\n",
      "Disalignment of:30738 found\n",
      "Acc data: 27298\n",
      "Gyro data: 58036\n",
      "Client Number 10 Activity : standing Orientation :chest\n",
      "Disalignment of:24932 found\n",
      "Acc data: 33068\n",
      "Gyro data: 58000\n",
      "Client Number 11 Activity : sitting Orientation :chest\n",
      "Disalignment of:16193 found\n",
      "Acc data: 31336\n",
      "Gyro data: 47529\n",
      "Client Number 12 Activity : climbingup Orientation :chest\n",
      "Disalignment of:66571 found\n",
      "Acc data: 28018\n",
      "Gyro data: 94589\n",
      "Client Number 14 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:19498 found\n",
      "Acc data: 7332\n",
      "Gyro data: 26830\n",
      "Client Number 14 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:15583 found\n",
      "Acc data: 6838\n",
      "Gyro data: 22421\n",
      "Client Number 14 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:18395 found\n",
      "Acc data: 6893\n",
      "Gyro data: 25288\n",
      "Client Number 14 Activity : climbingup Orientation :chest\n",
      "Disalignment of:10479 found\n",
      "Acc data: 9921\n",
      "Gyro data: 20400\n",
      "Client Number 14 Activity : climbingup Orientation :chest\n",
      "Disalignment of:2690 found\n",
      "Acc data: 9641\n",
      "Gyro data: 12331\n",
      "Client Number 14 Activity : walking Orientation :chest\n",
      "Disalignment of:42822 found\n",
      "Acc data: 33577\n",
      "Gyro data: 76399\n",
      "Client Number 8 Activity : climbingup Orientation :forearm\n",
      "Disalignment of:1002 found\n",
      "Acc data: 57528\n",
      "Gyro data: 58530\n",
      "Client Number 1 Activity : sitting Orientation :shin\n",
      "Disalignment of:59309 found\n",
      "Acc data: 32877\n",
      "Gyro data: 92186\n",
      "Client Number 14 Activity : climbingdown Orientation :upperarm\n",
      "Disalignment of:7544 found\n",
      "Acc data: 7331\n",
      "Gyro data: 14875\n",
      "Client Number 1 Activity : lying Orientation :waist\n",
      "Disalignment of:29601 found\n",
      "Acc data: 33237\n",
      "Gyro data: 62838\n",
      "Client Number 1 Activity : sitting Orientation :waist\n",
      "Disalignment of:42063 found\n",
      "Acc data: 32875\n",
      "Gyro data: 74938\n"
     ]
    }
   ],
   "source": [
    "# Reading and processing all data\n",
    "\n",
    "clientsOrientation = []\n",
    "\n",
    "nbAnomalies = 0 \n",
    "clientsAccDataByOrientation = []\n",
    "clientsGyroDataByOrientation = []\n",
    "clientsLabelByOrientation = []\n",
    "for orientation in orientations:\n",
    "    \n",
    "    xAccListClient = list()\n",
    "    xGyrListClient = list()\n",
    "    yListClient = list()\n",
    "    \n",
    "    for k in range(1,16):\n",
    "        xAccList = list()\n",
    "        xGyrList = list()\n",
    "        yList = list()\n",
    "        startingIndex = 0\n",
    "        \n",
    "        clientOrientation = []\n",
    "        \n",
    "        for activity in activities:\n",
    "            tempAcc = load_dataset('acc','REALWORLD',activity,orientation,0,k)\n",
    "            tempGyro = load_dataset('Gyroscope','REALWORLD',activity,orientation,0,k)\n",
    "            orientationLength = 0 \n",
    "            for i in range(0, len(tempAcc)):  \n",
    "                accDataLength = len(tempAcc[i])\n",
    "                gyroDataLength = len(tempGyro[i])\n",
    "                difference = accDataLength - gyroDataLength\n",
    "                differenceAbs = abs(difference)\n",
    "                differenceGyro = gyroDataLength - accDataLength\n",
    "                if(differenceGyro > 1000):\n",
    "                    print(\"Client Number \"+str(k) +\" Activity : \"+str(activity) + \" Orientation :\"+str(orientation))\n",
    "                    print(\"Disalignment of:\" +str(differenceAbs) + \" found\")\n",
    "                    print(\"Acc data: \"+str(accDataLength))\n",
    "                    print(\"Gyro data: \"+str(gyroDataLength))\n",
    "                    tempGyro[i] = resampy.resample(tempGyro[i], gyroDataLength, accDataLength,axis = 0)\n",
    "\n",
    "                tempAcc[i] = segmentData(tempAcc[i],128,64)\n",
    "                tempGyro[i] = segmentData(tempGyro[i],128,64)\n",
    "\n",
    "                accDataLength = len(tempAcc[i])\n",
    "                gyroDataLength = len(tempGyro[i])\n",
    "\n",
    "                difference = accDataLength - gyroDataLength\n",
    "                differenceAbs = abs(difference)\n",
    "                if(differenceAbs < 21):\n",
    "                    toAddShape = 0\n",
    "                    if(difference > 0):\n",
    "                        maxIndex = accDataLength-differenceAbs\n",
    "                        xAccList.append(tempAcc[i][:maxIndex,:])\n",
    "                        xGyrList.append(tempGyro[i])\n",
    "                        toAddShape = tempGyro[i].shape[0]\n",
    "                        yList.append(np.full((toAddShape), activities.index(activity)))   \n",
    "                    else:\n",
    "                        maxIndex = gyroDataLength-differenceAbs\n",
    "                        xAccList.append(tempAcc[i])\n",
    "                        xGyrList.append(tempGyro[i][:maxIndex,:])\n",
    "                        toAddShape = tempAcc[i].shape[0]\n",
    "                        yList.append(np.full((toAddShape), activities.index(activity)))\n",
    "#                     clientOrientation.append(np.full(toAddShape,orientationKeyMap[orientation]))\n",
    "#         clientsOrientation.append(np.hstack((clientOrientation)))\n",
    "        xAccListClient.append(np.vstack((xAccList)))\n",
    "        xGyrListClient.append(np.vstack((xGyrList)))\n",
    "        yListClient.append(np.hstack((yList)))\n",
    "    clientsAccDataByOrientation.append(np.asarray(xAccListClient, dtype=object))\n",
    "    clientsGyroDataByOrientation.append(np.asarray(xGyrListClient, dtype=object))\n",
    "    clientsLabelByOrientation.append(np.asarray(yListClient, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion to numpy array\n",
    "clientsAccDataByOrientation = np.asarray(clientsAccDataByOrientation, dtype=object)\n",
    "clientsGyroDataByOrientation = np.asarray(clientsGyroDataByOrientation, dtype=object)\n",
    "clientsLabelByOrientation = np.asarray(clientsLabelByOrientation, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking all partcipants client\n",
    "allAcc = np.vstack((np.ravel(clientsAccDataByOrientation)))\n",
    "allGyro = np.vstack((np.ravel(clientsGyroDataByOrientation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating features\n",
    "meanAcc = np.mean(allAcc)\n",
    "stdAcc = np.std(allAcc)\n",
    "\n",
    "meanGyro = np.mean(allGyro)\n",
    "stdGyro = np.std(allGyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel-wise z-normalization\n",
    "normalizedAcc = (clientsAccDataByOrientation - meanAcc)/stdAcc\n",
    "normalizedGyro = (clientsGyroDataByOrientation - meanGyro)/stdGyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedOrientationData = []\n",
    "for normAcc,normGyro in zip(normalizedAcc,normalizedGyro):\n",
    "    stackedOrientationData.append(np.asarray([np.dstack((normAcc,normGyro)) for normAcc,normGyro in zip(normAcc,normGyro)],dtype=object))\n",
    "stackedOrientationData = np.asarray(stackedOrientationData, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = 'RealWorld'\n",
    "os.makedirs('datasetStandardized/'+dataName, exist_ok=True)\n",
    "hkl.dump(stackedOrientationData,'datasetStandardized/'+dataName+ '/clientsData.hkl' )\n",
    "hkl.dump(clientsLabelByOrientation,'datasetStandardized/'+dataName+ '/clientsLabel.hkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "har",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
