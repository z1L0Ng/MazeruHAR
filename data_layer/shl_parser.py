"""
SHLæ•°æ®è§£æå™¨ - ä¿®æ­£ç‰ˆæœ¬ï¼ˆåŸºäºçœŸå®ä¼ æ„Ÿå™¨ï¼‰
"""

import os
import numpy as np
import pandas as pd
import hickle as hkl
from typing import Dict, List, Tuple, Any
import logging

try:
    from .base_parser import DataParser
except ImportError:
    try:
        from data_layer.base_parser import DataParser
    except ImportError:
        from base_parser import DataParser


class SHLDataParser(DataParser):
    """
    SHLæ•°æ®é›†è§£æå™¨ - åŸºäºçœŸå®ä¼ æ„Ÿå™¨é…ç½®
    æ”¯æŒ6ç§ä¼ æ„Ÿå™¨ç±»å‹ï¼šIMUã€ç£åŠ›è®¡ã€æ–¹å‘ã€é‡åŠ›ã€çº¿æ€§åŠ é€Ÿåº¦
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.window_size = config.get('window_size', 128)
        self.step_size = config.get('step_size', 64)
        self.sample_rate = config.get('sample_rate', 100)
        self.normalize_per_sample = config.get('normalize_per_sample', True)
        
        # SHLæ•°æ®é›†çš„æ´»åŠ¨æ ‡ç­¾æ˜ å°„ (å¤„ç†åçš„0-based)
        self.activity_labels = {
            0: 'Still', 1: 'Walking', 2: 'Run', 3: 'Bike',
            4: 'Car', 5: 'Bus', 6: 'Train', 7: 'Subway'
        }
        
        # çœŸå®çš„SHLä¼ æ„Ÿå™¨é…ç½®
        self.sensor_column_mapping = {
            'acc': [1, 2, 3],           # åŠ é€Ÿåº¦è®¡
            'gyro': [4, 5, 6],          # é™€èºä»ª
            'mag': [7, 8, 9],           # ç£åŠ›è®¡
            'ori': [10, 11, 12, 13],    # æ–¹å‘å››å…ƒæ•°
            'gra': [14, 15, 16],        # é‡åŠ›
            'lacc': [17, 18, 19]        # çº¿æ€§åŠ é€Ÿåº¦
        }
        
        # æ¨¡æ€é…ç½®
        self.modalities_config = config.get('modalities', {})
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        
        # æ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹
        self.split_ratios = {
            'train': 0.7,
            'val': 0.15, 
            'test': 0.15
        }

    def load_preprocessed_data(self) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """ä»é¢„å¤„ç†çš„HKLæ–‡ä»¶åŠ è½½æ•°æ®"""
        data_file = os.path.join(self.data_path, 'clientsData.hkl')
        label_file = os.path.join(self.data_path, 'clientsLabel.hkl')
        
        if not os.path.exists(data_file):
            raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        if not os.path.exists(label_file):
            raise FileNotFoundError(f"æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {label_file}")
        
        self.logger.info(f"ä» {self.data_path} åŠ è½½é¢„å¤„ç†æ•°æ®...")
        
        clients_data = hkl.load(data_file)
        clients_labels = hkl.load(label_file)
        
        self.logger.info(f"æˆåŠŸåŠ è½½ {len(clients_data)} ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®")
        
        return clients_data, clients_labels

    def split_modalities(self, data: np.ndarray) -> Dict[str, np.ndarray]:
        """
        å°†19ç»´æ•°æ®æ‹†åˆ†ä¸ºä¸åŒçš„ä¼ æ„Ÿå™¨æ¨¡æ€
        
        Args:
            data: å½¢çŠ¶ä¸º (time_steps, 19) çš„æ•°æ®
            
        Returns:
            æ¨¡æ€å­—å…¸ï¼Œæ¯ä¸ªé”®å¯¹åº”ä¸€ç§ä¼ æ„Ÿå™¨ç±»å‹
        """
        modalities = {}
        
        # æ ¹æ®é…ç½®æ–‡ä»¶ä¸­å¯ç”¨çš„æ¨¡æ€è¿›è¡Œæ‹†åˆ†
        for modality_name, modality_config in self.modalities_config.items():
            if not modality_config.get('enabled', False):
                continue
                
            # è·å–åˆ—ç´¢å¼•
            column_indices = modality_config.get('column_indices', [])
            if not column_indices:
                # å¦‚æœæ²¡æœ‰ç›´æ¥æŒ‡å®šåˆ—ç´¢å¼•ï¼Œæ ¹æ®ä¼ æ„Ÿå™¨åç§°æ¨æ–­
                sensors = modality_config.get('sensors', [])
                column_indices = []
                for sensor in sensors:
                    if sensor in self.sensor_column_mapping:
                        column_indices.extend(self.sensor_column_mapping[sensor])
            
            if column_indices:
                # è°ƒæ•´ç´¢å¼•ï¼ˆä»1-basedè½¬ä¸º0-basedï¼‰
                adjusted_indices = [idx - 1 for idx in column_indices if idx > 0]
                
                # æå–å¯¹åº”åˆ—çš„æ•°æ®
                if max(adjusted_indices) < data.shape[1]:
                    modality_data = data[:, adjusted_indices]
                    modalities[modality_name] = modality_data
                    self.logger.debug(f"æå– {modality_name}: å½¢çŠ¶ {modality_data.shape}")
                else:
                    self.logger.warning(f"æ¨¡æ€ {modality_name} çš„åˆ—ç´¢å¼•è¶…å‡ºæ•°æ®èŒƒå›´")
        
        return modalities

    def parse_data(self, split: str) -> Tuple[List[Dict[str, np.ndarray]], List[int]]:
        """
        è§£ææ•°æ®å¹¶è¿”å›æ¨¡æ€å­—å…¸æ ¼å¼
        """
        self.logger.info(f"ğŸš€ å¼€å§‹è§£æ {split} æ•°æ®é›†...")
        
        # åŠ è½½é¢„å¤„ç†æ•°æ®
        all_data, all_labels = self.load_preprocessed_data()
        
        if not all_data:
            raise ValueError("æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æ•°æ®")
        
        # æ•°æ®é›†åˆ’åˆ†
        total_samples = len(all_data)
        if split == 'train':
            start_idx = 0
            end_idx = int(total_samples * self.split_ratios['train'])
        elif split == 'val':
            start_idx = int(total_samples * self.split_ratios['train'])
            end_idx = start_idx + int(total_samples * self.split_ratios['val'])
        else:  # test
            start_idx = int(total_samples * (self.split_ratios['train'] + self.split_ratios['val']))
            end_idx = total_samples
        
        split_data = all_data[start_idx:end_idx]
        split_labels = all_labels[start_idx:end_idx]
        
        self.logger.info(f"{split} æ•°æ®é›†: {len(split_data)} æ ·æœ¬")
        
        # åˆ†ç¦»å¤šæ¨¡æ€æ•°æ®
        self.logger.info("åˆ†ç¦»å¤šæ¨¡æ€æ•°æ®...")
        processed_data = []
        
        for i, data in enumerate(split_data):
            try:
                modalities = self.split_modalities(data)
                processed_data.append(modalities)
            except Exception as e:
                self.logger.error(f"å¤„ç†æ ·æœ¬ {i} æ—¶å‡ºé”™: {e}")
                raise
        
        self.logger.info(f"æˆåŠŸè§£æ {len(processed_data)} ä¸ªæ ·æœ¬")
        
        # æ‰“å°ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ¨¡æ€ä¿¡æ¯
        if processed_data:
            first_sample = processed_data[0]
            self.logger.info("ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ¨¡æ€ä¿¡æ¯:")
            for modality, data in first_sample.items():
                self.logger.info(f"  {modality}: {data.shape}")
        
        return processed_data, split_labels

    def get_num_classes(self) -> int:
        """è¿”å›ç±»åˆ«æ•°"""
        return len(self.activity_labels)

    def get_class_names(self) -> List[str]:
        """è¿”å›ç±»åˆ«åç§°åˆ—è¡¨"""
        return list(self.activity_labels.values())

    def get_modality_info(self) -> Dict[str, Any]:
        """è¿”å›æ¨¡æ€ä¿¡æ¯"""
        modality_info = {}
        for modality_name, config in self.modalities_config.items():
            if config.get('enabled', False):
                modality_info[modality_name] = {
                    'channels': config.get('channels', 0),
                    'sensors': config.get('sensors', []),
                    'enabled': True
                }
        return modality_info