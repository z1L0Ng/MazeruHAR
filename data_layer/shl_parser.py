# æ‰©å±•çš„SHLæ•°æ®è§£æå™¨ - æœ€å°åŒ–ä¿®æ”¹ç‰ˆæœ¬
# æ–‡ä»¶è·¯å¾„: data_layer/shl_parser.py

import os
import numpy as np
import pandas as pd
import hickle as hkl
from typing import Dict, List, Tuple, Any
from scipy import signal
import logging

# ä¿®å¤å¯¼å…¥é”™è¯¯ - ä½¿ç”¨ç»å¯¹å¯¼å…¥
try:
    from base_parser import DataParser
except ImportError:
    # å¦‚æœåœ¨åŒ…å†…è¿è¡Œï¼Œå°è¯•ç›¸å¯¹å¯¼å…¥
    from .base_parser import DataParser


class SHLDataParser(DataParser):
    """
    SHLæ•°æ®é›†è§£æå™¨ - æ‰©å±•ç‰ˆæœ¬
    æ”¯æŒä»é¢„å¤„ç†çš„HKLæ–‡ä»¶åŠ è½½æ•°æ®ï¼Œå¹¶æ”¯æŒæ›´å¤šä¼ æ„Ÿå™¨æ¨¡æ€
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.window_size = config.get('window_size', 128)
        self.step_size = config.get('step_size', 64)
        self.sample_rate = config.get('sample_rate', 100)
        self.normalize_per_sample = config.get('normalize_per_sample', True)
        
        # SHLæ•°æ®é›†çš„æ´»åŠ¨æ ‡ç­¾æ˜ å°„ (0-based)
        self.activity_labels = {
            0: 'Standing', 1: 'Walking', 2: 'Running', 3: 'Biking',
            4: 'Car', 5: 'Bus', 6: 'Train', 7: 'Subway'
        }
        
        # æ‰©å±•çš„æ¨¡æ€é…ç½®
        self.modalities_config = config.get('modalities', {
            'imu': {'enabled': True, 'channels': 6},
            'pressure': {'enabled': True, 'channels': 1}
        })
        
        # SHLæ•°æ®é›†ä¸­ä¼ æ„Ÿå™¨çš„åˆ—ç´¢å¼•æ˜ å°„ï¼ˆåŸºäº_Motion.txtæ–‡ä»¶æ ¼å¼ï¼‰
        self.sensor_column_mapping = {
            'accelerometer': [1, 2, 3],      # åŠ é€Ÿåº¦è®¡ x, y, z
            'gyroscope': [4, 5, 6],          # é™€èºä»ª x, y, z  
            'magnetometer': [7, 8, 9],       # ç£åŠ›è®¡ x, y, z
            'orientation': [10, 11, 12, 13], # æ–¹å‘å››å…ƒæ•° w, x, y, z
            'gravity': [14, 15, 16],         # é‡åŠ› x, y, z
            'linear_acceleration': [17, 18, 19], # çº¿æ€§åŠ é€Ÿåº¦ x, y, z
            'pressure': [20]                 # æ°”å‹ï¼ˆå‡è®¾åœ¨ç¬¬20åˆ—ï¼‰
        }
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        
        # æ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹
        self.split_ratios = {
            'train': 0.7,
            'val': 0.15, 
            'test': 0.15
        }

    def load_preprocessed_data(self) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """ä»é¢„å¤„ç†çš„HKLæ–‡ä»¶åŠ è½½æ•°æ®"""
        data_file = os.path.join(self.data_path, 'clientsData.hkl')
        label_file = os.path.join(self.data_path, 'clientsLabel.hkl')
        
        if not os.path.exists(data_file):
            raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        
        if not os.path.exists(label_file):
            raise FileNotFoundError(f"æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {label_file}")
        
        self.logger.info(f"ä» {data_file} åŠ è½½æ•°æ®...")
        clients_data = hkl.load(data_file)
        
        self.logger.info(f"ä» {label_file} åŠ è½½æ ‡ç­¾...")
        clients_labels = hkl.load(label_file)
        
        self.logger.info(f"åŠ è½½äº† {len(clients_data)} ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®")
        
        return clients_data, clients_labels

    def validate_and_clean_data(self, clients_data: List[np.ndarray], 
                               clients_labels: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:
        """éªŒè¯å’Œæ¸…ç†æ•°æ®"""
        self.logger.info("éªŒè¯å’Œæ¸…ç†æ•°æ®...")
        
        valid_data = []
        valid_labels = []
        
        for i, (data, labels) in enumerate(zip(clients_data, clients_labels)):
            if data is None or labels is None:
                self.logger.warning(f"è·³è¿‡ç©ºæ•°æ®å®¢æˆ·ç«¯ {i}")
                continue
            
            if len(data) != len(labels):
                self.logger.warning(f"å®¢æˆ·ç«¯ {i} æ•°æ®å’Œæ ‡ç­¾é•¿åº¦ä¸åŒ¹é…ï¼Œè·³è¿‡")
                continue
            
            if len(data) == 0:
                self.logger.warning(f"å®¢æˆ·ç«¯ {i} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                continue
            
            # æ£€æŸ¥æ•°æ®å½¢çŠ¶
            if data.ndim != 3:
                self.logger.warning(f"å®¢æˆ·ç«¯ {i} æ•°æ®ç»´åº¦é”™è¯¯: {data.shape}")
                continue
                
            valid_data.append(data)
            valid_labels.append(labels)
        
        if not valid_data:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®")
        
        # åˆå¹¶æ‰€æœ‰å®¢æˆ·ç«¯çš„æ•°æ®
        all_data = np.vstack(valid_data)
        all_labels = np.hstack(valid_labels)
        
        self.logger.info(f"æœ‰æ•ˆæ•°æ®å½¢çŠ¶: {all_data.shape}")
        self.logger.info(f"æœ‰æ•ˆæ ‡ç­¾å½¢çŠ¶: {all_labels.shape}")
        
        return all_data, all_labels

    def normalize_data(self, data: np.ndarray) -> np.ndarray:
        """æ•°æ®æ ‡å‡†åŒ–"""
        if self.normalize_per_sample:
            # æ ·æœ¬çº§æ ‡å‡†åŒ–ï¼šæ¯ä¸ªæ ·æœ¬ç‹¬ç«‹æ ‡å‡†åŒ–
            normalized_data = []
            for sample in data:
                # æ²¿æ—¶é—´è½´è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
                mean = np.mean(sample, axis=0, keepdims=True)
                std = np.std(sample, axis=0, keepdims=True)
                std = np.where(std == 0, 1, std)  # é¿å…é™¤é›¶
                normalized_sample = (sample - mean) / std
                normalized_data.append(normalized_sample)
            return np.array(normalized_data)
        else:
            # å…¨å±€æ ‡å‡†åŒ–
            original_shape = data.shape
            reshaped_data = data.reshape(-1, original_shape[-1])
            
            mean = np.mean(reshaped_data, axis=0)
            std = np.std(reshaped_data, axis=0)
            std = np.where(std == 0, 1, std)
            
            normalized_reshaped = (reshaped_data - mean) / std
            return normalized_reshaped.reshape(original_shape)

    # ç«‹å³æ›¿æ¢ data_layer/shl_parser.py ä¸­çš„ split_modalities å‡½æ•°

def split_modalities(self, data: np.ndarray) -> Dict[str, np.ndarray]:
    """
    å°†å¤šæ¨¡æ€æ•°æ®åˆ†ç¦» - ä¿®å¤ç‰ˆæœ¬ï¼Œæ”¯æŒç£åŠ›è®¡
    """
    modalities = {}
    total_channels = data.shape[-1]
    self.logger.info(f"ğŸ” DEBUG: è¾“å…¥æ•°æ®å½¢çŠ¶={data.shape}, æ€»é€šé“æ•°={total_channels}")
    self.logger.info(f"ğŸ” DEBUG: é…ç½®çš„æ¨¡æ€={list(self.modalities_config.keys())}")

    # æ‰“å°æ¯ä¸ªæ¨¡æ€çš„å¯ç”¨çŠ¶æ€
    for modality_name, modality_config in self.modalities_config.items():
        enabled = modality_config.get('enabled', False)
        self.logger.info(f"ğŸ” DEBUG: æ¨¡æ€ {modality_name} - enabled={enabled}")

    # æ£€æŸ¥å¯ç”¨çš„æ¨¡æ€å¹¶åˆ†ç¦»æ•°æ®
    for modality_name, modality_config in self.modalities_config.items():
        if not modality_config.get('enabled', False):
            self.logger.info(f"â­ï¸  è·³è¿‡æœªå¯ç”¨çš„æ¨¡æ€: {modality_name}")
            continue

        self.logger.info(f"ğŸ”„ æ­£åœ¨å¤„ç†å¯ç”¨çš„æ¨¡æ€: {modality_name}")

        if modality_name == 'imu':
            # IMUæ¨¡æ€ï¼šåŠ é€Ÿåº¦è®¡(3) + é™€èºä»ª(3) = 6é€šé“
            if total_channels >= 6:
                acc_data = data[:, :, 0:3]    # åŠ é€Ÿåº¦è®¡
                gyro_data = data[:, :, 3:6]   # é™€èºä»ª
                imu_data = np.concatenate([acc_data, gyro_data], axis=-1)
                modalities['imu'] = imu_data
                self.logger.info(f"âœ… æå–IMUæ¨¡æ€: {imu_data.shape}")
            else:
                self.logger.warning("âŒ æ•°æ®é€šé“ä¸è¶³ï¼Œæ— æ³•æå–IMUæ¨¡æ€")

        elif modality_name == 'pressure':
            # å‹åŠ›æ¨¡æ€ï¼šä½¿ç”¨æœ€åä¸€åˆ—ä½œä¸ºå‹åŠ›æ•°æ®
            if total_channels >= 7:
                # ä½¿ç”¨å€’æ•°ç¬¬ä¸€åˆ—ä½œä¸ºå‹åŠ›æ•°æ®
                modalities['pressure'] = data[:, :, -1:]
                self.logger.info(f"âœ… æå–å‹åŠ›æ¨¡æ€: {modalities['pressure'].shape}")
            else:
                # åˆ›å»ºè™šæ‹Ÿå‹åŠ›æ•°æ®
                self.logger.warning("âš ï¸  æ•°æ®é€šé“ä¸è¶³ï¼Œåˆ›å»ºè™šæ‹Ÿå‹åŠ›æ•°æ®")
                modalities['pressure'] = np.zeros((data.shape[0], data.shape[1], 1))

        elif modality_name == 'magnetometer':
            # ç£åŠ›è®¡æ¨¡æ€ï¼šåˆ—6-8 (åŸºäºSHLæ•°æ®é›†æ ‡å‡†æ ¼å¼)
            self.logger.info(f"ğŸ” å¤„ç†ç£åŠ›è®¡: total_channels={total_channels}, éœ€è¦>=9")
            if total_channels >= 9:
                magnetometer_data = data[:, :, 6:9]
                modalities['magnetometer'] = magnetometer_data
                self.logger.info(f"âœ… æˆåŠŸæå–ç£åŠ›è®¡æ¨¡æ€: {magnetometer_data.shape}")
                # é¢å¤–è°ƒè¯•ä¿¡æ¯
                self.logger.info(f"ğŸ” ç£åŠ›è®¡æ•°æ®ç»Ÿè®¡: min={magnetometer_data.min():.3f}, max={magnetometer_data.max():.3f}, mean={magnetometer_data.mean():.3f}")
            else:
                self.logger.warning(f"âŒ æ•°æ®é€šé“ä¸è¶³({total_channels})ï¼Œæ— æ³•æå–ç£åŠ›è®¡æ¨¡æ€(éœ€è¦9é€šé“)")

        elif modality_name == 'orientation':
            # æ–¹å‘æ¨¡æ€ï¼šåˆ—9-12 (å››å…ƒæ•°)
            if total_channels >= 13:
                modalities['orientation'] = data[:, :, 9:13]
                self.logger.info(f"âœ… æå–æ–¹å‘æ¨¡æ€: {modalities['orientation'].shape}")
            else:
                self.logger.warning(f"âŒ æ•°æ®é€šé“ä¸è¶³({total_channels})ï¼Œæ— æ³•æå–æ–¹å‘æ¨¡æ€(éœ€è¦13é€šé“)")

        elif modality_name == 'gravity':
            # é‡åŠ›æ¨¡æ€ï¼šåˆ—13-15
            if total_channels >= 16:
                modalities['gravity'] = data[:, :, 13:16]
                self.logger.info(f"âœ… æå–é‡åŠ›æ¨¡æ€: {modalities['gravity'].shape}")
            else:
                self.logger.warning(f"âŒ æ•°æ®é€šé“ä¸è¶³({total_channels})ï¼Œæ— æ³•æå–é‡åŠ›æ¨¡æ€(éœ€è¦16é€šé“)")

        elif modality_name == 'linear_acceleration':
            # çº¿æ€§åŠ é€Ÿåº¦æ¨¡æ€ï¼šåˆ—16-18
            if total_channels >= 19:
                modalities['linear_acceleration'] = data[:, :, 16:19]
                self.logger.info(f"âœ… æå–çº¿æ€§åŠ é€Ÿåº¦æ¨¡æ€: {modalities['linear_acceleration'].shape}")
            else:
                self.logger.warning(f"âŒ æ•°æ®é€šé“ä¸è¶³({total_channels})ï¼Œæ— æ³•æå–çº¿æ€§åŠ é€Ÿåº¦æ¨¡æ€(éœ€è¦19é€šé“)")

        else:
            self.logger.warning(f"âš ï¸  æœªçŸ¥çš„æ¨¡æ€ç±»å‹: {modality_name}")

    if not modalities:
        raise ValueError("âŒ æ²¡æœ‰æˆåŠŸæå–ä»»ä½•æ¨¡æ€æ•°æ®")

    # æ‰“å°æœ€ç»ˆæå–çš„æ¨¡æ€æ€»ç»“
    self.logger.info(f"ğŸ¯ æœ€ç»ˆæˆåŠŸæå–çš„æ¨¡æ€: {list(modalities.keys())}")
    for modality_name, modality_data in modalities.items():
        self.logger.info(f"   ğŸ“Š {modality_name}: {modality_data.shape}")

    return modalities


# å¿«é€Ÿæµ‹è¯•å‡½æ•°
def test_shl_parser():
    """æµ‹è¯•SHLè§£æå™¨"""
    print("æµ‹è¯•æ‰©å±•çš„SHLæ•°æ®è§£æå™¨...")
    
    # æµ‹è¯•é…ç½® - åŒ…å«æ›´å¤šä¼ æ„Ÿå™¨
    config = {
        'name': 'SHL',
        'data_path': 'datasets/datasetStandardized/SHL_Multimodal/',
        'window_size': 128,
        'step_size': 64,
        'sample_rate': 100,
        'normalize_per_sample': True,
        'modalities': {
            'imu': {'enabled': True, 'channels': 6},
            'pressure': {'enabled': True, 'channels': 1},
            'magnetometer': {'enabled': True, 'channels': 3},
            'orientation': {'enabled': False, 'channels': 4},  # å¯é€‰å¯ç”¨
            'gravity': {'enabled': False, 'channels': 3},      # å¯é€‰å¯ç”¨
            'linear_acceleration': {'enabled': False, 'channels': 3}  # å¯é€‰å¯ç”¨
        }
    }
    
    try:
        parser = SHLDataParser(config)
        
        # æµ‹è¯•è®­ç»ƒæ•°æ®è§£æ
        train_data, train_labels = parser.parse_data('train')
        print(f"âœ“ è®­ç»ƒæ•°æ®è§£ææˆåŠŸ: {len(train_data)} æ ·æœ¬")
        
        # è·å–æ¨¡æ€ä¿¡æ¯
        modality_info = parser.get_modality_info()
        print(f"âœ“ æ”¯æŒçš„æ¨¡æ€: {list(modality_info.keys())}")
        
        # æ‰“å°ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ¨¡æ€ä¿¡æ¯
        if train_data:
            first_sample = train_data[0]
            print("âœ“ ç¬¬ä¸€ä¸ªæ ·æœ¬åŒ…å«çš„æ¨¡æ€:")
            for modality, data in first_sample.items():
                print(f"    {modality}: {data.shape}")
        
        print("âœ“ æ‰©å±•çš„SHLæ•°æ®è§£æå™¨æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âœ— æ‰©å±•çš„SHLæ•°æ®è§£æå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] - %(message)s')
    
    # è¿è¡Œæµ‹è¯•
    test_shl_parser()