{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde03824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "\n",
    "def pick_free_gpu(threshold_mb=2000):\n",
    "    result = subprocess.run(\n",
    "        [\"nvidia-smi\", \"--query-gpu=memory.free\", \"--format=csv,nounits,noheader\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    gpu_memory = [int(x) for x in result.stdout.strip().split('\\n')]\n",
    "    for idx, mem in enumerate(gpu_memory):\n",
    "        if mem > threshold_mb:\n",
    "            return str(idx)\n",
    "    return None\n",
    "\n",
    "# 使用\n",
    "gpu_id = pick_free_gpu()\n",
    "if gpu_id is None:\n",
    "    raise RuntimeError(\"❌ 没有空闲 GPU，退出训练\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_id\n",
    "print(f\"✅ 使用 GPU:{gpu_id}\")\n",
    "\n",
    "randomSeed = 1\n",
    "os.environ['PYTHONHASHSEED']=str(randomSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec11e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "import csv\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import hickle as hkl \n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import shutil\n",
    "import gc\n",
    "import sys\n",
    "import sklearn.manifold\n",
    "import seaborn as sns\n",
    "import argparse\n",
    "import matplotlib.gridspec as gridspec\n",
    "import __main__ as main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model \n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50500d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which CPU/GPU to use\n",
    "# \"-1,0,1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Set The Default Hyperparameters Here\n",
    "\n",
    "architecture = \"HART\"\n",
    "# MobileHART, HART\n",
    "\n",
    "# RealWorld,HHAR,UCI,SHL,MotionSense, COMBINED\n",
    "dataSetName = 'RealWorld'\n",
    "\n",
    "#BALANCED, UNBALANCED\n",
    "dataConfig = \"BALANCED\"\n",
    "\n",
    "# Show training verbose: 0,1\n",
    "showTrainVerbose = 1\n",
    "\n",
    "# input window size \n",
    "segment_size = 128\n",
    "\n",
    "# input channel count\n",
    "num_input_channels = 6\n",
    "\n",
    "learningRate = 5e-3\n",
    "\n",
    "# model drop out rate\n",
    "dropout_rate = 0.3\n",
    "\n",
    "# local epoch\n",
    "localEpoch = 200\n",
    "# or 4 \n",
    "frameLength = 16\n",
    "\n",
    "timeStep = 16\n",
    "\n",
    "positionDevice = ''\n",
    "# ['chest','forearm','head','shin','thigh','upperarm','waist']\n",
    "# ['nexus4', 'lgwatch','s3', 's3mini','gear','samsungold']\n",
    "tokenBased = False\n",
    "\n",
    "measureEnergy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter for the model\n",
    "\n",
    "batch_size = 256\n",
    "projection_dim = 192\n",
    "filterAttentionHead = 4\n",
    "\n",
    "# To adjust the number of blocks in for HART, Add or remove the conv kernel size here\n",
    "# each conv kernel length is for one HART block\n",
    "convKernels = [3, 7, 15, 31, 31, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cbcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fit_args(parser):\n",
    "    \"\"\"\n",
    "    parser : argparse.ArgumentParser\n",
    "    return a parser added with args required by fit\n",
    "    \"\"\"\n",
    "    # Training settings\n",
    "    parser.add_argument('--batch_size', type=int, default=batch_size, \n",
    "                        help='Batch size of the training')  \n",
    "    parser.add_argument('--localEpoch', type=int, default=localEpoch, \n",
    "                        help='Number of epochs for training')  \n",
    "    parser.add_argument('--architecture', type=str, default=architecture, \n",
    "                        help='Choose between HART or MobileHART')  \n",
    "    parser.add_argument('--projection_dim', type=int, default=projection_dim, \n",
    "                        help='Size of the projection dimensions')  \n",
    "    parser.add_argument('--frame_length', type=int, default=frameLength, \n",
    "                help='Patch Size')  \n",
    "    parser.add_argument('--time_step', type=int, default=timeStep, \n",
    "            help='Stride Size')  \n",
    "    parser.add_argument('--dataset', type=str, default=dataSetName, \n",
    "        help='Dataset')  \n",
    "    parser.add_argument('--tokenBased', type=bool, default=tokenBased, \n",
    "        help='Use Token or Global Average Pooling')  \n",
    "    parser.add_argument('--positionDevice', type=str, default=positionDevice, \n",
    "        help='Test is done other position not in training, if empty, uses a 70/10/20 train/dev/test ratio ')  \n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d776b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interactive():\n",
    "    return not hasattr(main, '__file__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_interactive():\n",
    "    args = add_fit_args(argparse.ArgumentParser(description='Human Activity Recognition Transformer'))\n",
    "    localEpoch = args.localEpoch\n",
    "    batch_size = args.batch_size\n",
    "    architecture = args.architecture\n",
    "    projection_dim = args.projection_dim\n",
    "    frameLength = args.frame_length\n",
    "    timeStep = args.time_step\n",
    "    dataSetName = args.dataset\n",
    "    tokenBased = args.tokenBased\n",
    "    positionDevice = args.positionDevice\n",
    "    \n",
    "input_shape = (segment_size,num_input_channels)\n",
    "projectionHalf = projection_dim//2\n",
    "projectionQuarter = projection_dim//4\n",
    "\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "\n",
    "R = projectionHalf // filterAttentionHead\n",
    "assert R * filterAttentionHead == projectionHalf\n",
    "\n",
    "\n",
    "segmentTime = [x for x in range(0,segment_size - frameLength + timeStep,timeStep)]\n",
    "assert R * filterAttentionHead == projectionHalf\n",
    "if(positionDevice != ''):\n",
    "    assert dataSetName == \"RealWorld\" or dataSetName == \"HHAR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying activities and where the results will be stored \n",
    "if(dataSetName == 'UCI'):\n",
    "    ACTIVITY_LABEL = ['Walking', 'Upstair','Downstair', 'Sitting', 'Standing', 'Lying']\n",
    "elif(dataSetName == \"RealWorld\"):\n",
    "    ACTIVITY_LABEL = ['Downstairs','Upstairs', 'Jumping','Lying', 'Running', 'Sitting', 'Standing', 'Walking']\n",
    "elif(dataSetName == \"MotionSense\"):\n",
    "    ACTIVITY_LABEL = ['Downstairs', 'Upstairs', 'Sitting', 'Standing', 'Walking', 'Jogging']\n",
    "elif(dataSetName == \"HHAR\"):\n",
    "    ACTIVITY_LABEL = ['Sitting', 'Standing', 'Walking', 'Upstair', 'Downstairs', 'Biking']\n",
    "else:\n",
    "#     SHL\n",
    "    ACTIVITY_LABEL = ['Standing','Walking','Runing','Biking','Car','Bus','Train','Subway']\n",
    "\n",
    "activityCount = len(ACTIVITY_LABEL)\n",
    "\n",
    "architectureType = str(architecture)+'_'+str(int(frameLength))+'frameLength_'+str(timeStep)+'TimeStep_'+str(projection_dim)+\"ProjectionSize_\"+str(learningRate)+'LR'\n",
    "if(tokenBased):\n",
    "    architectureType = architectureType + \"_tokenBased\"\n",
    "    \n",
    "if(positionDevice != ''):\n",
    "    architectureType = architectureType + \"_PositionWise_\" + str(positionDevice)\n",
    "mainDir = './'\n",
    "\n",
    "if(localEpoch < 20):\n",
    "    architectureType =  \"Tests/\"+str(architectureType)\n",
    "filepath = mainDir +'HART_Results/'+architectureType+'/'+dataSetName+'/'\n",
    "os.makedirs(filepath, exist_ok=True)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "attentionPath = filepath+\"attentionImages/\"\n",
    "os.makedirs(attentionPath, exist_ok=True)\n",
    "\n",
    "bestModelPath = filepath + 'bestModels/'\n",
    "os.makedirs(bestModelPath, exist_ok=True)\n",
    "\n",
    "currentModelPath = filepath + 'currentModels/'\n",
    "os.makedirs(currentModelPath, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "np.random.seed(randomSeed)\n",
    "tf.keras.utils.set_random_seed(randomSeed)\n",
    "tf.random.set_seed(randomSeed)\n",
    "random.seed(randomSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(dataSetName == \"COMBINED\"):\n",
    "    datasetList = [\"UCI\",\"RealWorld\",\"HHAR\", \"MotionSense\",\"SHL_128\"]\n",
    "    ACTIVITY_LABEL = ['Walk', 'Upstair', 'Downstair', 'Sit', 'Stand', 'Lay', 'Jump','Run', 'Bike', 'Car', 'Bus', 'Train', 'Subway']\n",
    "    activityCount = len(ACTIVITY_LABEL)\n",
    "    UCI = [0,1,2,3,4,5]\n",
    "    REALWORLD_CLIENT = [2,1,6,5,7,3,4,0]\n",
    "    HHAR = [3,4,0,1,2,8]\n",
    "    MotionSense = [2,1,3,4,0,7]\n",
    "    SHL = [4,0,7,8,9,10,11,12]\n",
    "\n",
    "    centralTrainData = []\n",
    "    centralTrainLabel = []\n",
    "    centralTestData = []\n",
    "    centralTestLabel = []\n",
    "    for dataSetName in datasetList:\n",
    "        clientCount = utils.returnClientByDataset(dataSetName) \n",
    "        loadedDataset = utils.loadDataset(dataSetName,clientCount,dataConfig,randomSeed,mainDir+'datasets/')\n",
    "        centralTrainData.append(loadedDataset.centralTrainData)\n",
    "        centralTrainLabel.append(loadedDataset.centralTrainLabel)\n",
    "        centralTestData.append(loadedDataset.centralTestData)\n",
    "        centralTestLabel.append(loadedDataset.centralTestLabel)\n",
    "        print(dataSetName + \" has class :\" +str(np.unique(centralTrainLabel[-1])))\n",
    "        del loadedDataset\n",
    "\n",
    "    centralTestLabelAligned = []\n",
    "    centralTrainLabelAligned = []\n",
    "    combinedAlignedData = centralTestData\n",
    "    for index, datasetName in enumerate(datasetList):\n",
    "        if(datasetName == 'UCI'):\n",
    "            centralTrainLabelAligned.append(centralTrainLabel[index])\n",
    "            centralTestLabelAligned.append(centralTestLabel[index])\n",
    "        elif(datasetName == 'RealWorld'):\n",
    "            centralTrainLabelAligned.append(np.hstack([REALWORLD_CLIENT[labelIndex] for labelIndex in centralTrainLabel[index]]))\n",
    "            centralTestLabelAligned.append(np.hstack([REALWORLD_CLIENT[labelIndex] for labelIndex in centralTestLabel[index]]))\n",
    "\n",
    "        elif(datasetName == 'HHAR'):\n",
    "            centralTrainLabelAligned.append(np.hstack([HHAR[labelIndex] for labelIndex in centralTrainLabel[index]]))\n",
    "            centralTestLabelAligned.append(np.hstack([HHAR[labelIndex] for labelIndex in centralTestLabel[index]]))\n",
    "        elif(datasetName == 'MotionSense'):\n",
    "            centralTrainLabelAligned.append(np.hstack([MotionSense[labelIndex] for labelIndex in centralTrainLabel[index]]))\n",
    "            centralTestLabelAligned.append(np.hstack([MotionSense[labelIndex] for labelIndex in centralTestLabel[index]]))\n",
    "        else:\n",
    "            centralTrainLabelAligned.append(np.hstack([SHL[labelIndex] for labelIndex in centralTrainLabel[index]]))\n",
    "            centralTestLabelAligned.append(np.hstack([SHL[labelIndex] for labelIndex in centralTestLabel[index]]))\n",
    "    centralTrainData = np.vstack((centralTrainData))\n",
    "    centralTestData = np.vstack((centralTestData))\n",
    "    centralTrainLabel = np.hstack((centralTrainLabelAligned))\n",
    "    centralTestLabel = np.hstack((centralTestLabelAligned))\n",
    "else:\n",
    "    clientCount = utils.returnClientByDataset(dataSetName)\n",
    "    datasetLoader = utils.loadDataset(dataSetName,clientCount,dataConfig,randomSeed,mainDir+'datasets/')\n",
    "    centralTrainData = datasetLoader.centralTrainData \n",
    "    centralTrainLabel = datasetLoader.centralTrainLabel \n",
    "\n",
    "    centralTestData = datasetLoader.centralTestData \n",
    "    centralTestLabel = datasetLoader.centralTestLabel \n",
    "\n",
    "    clientOrientationTrain = datasetLoader.clientOrientationTrain \n",
    "    clientOrientationTest = datasetLoader.clientOrientationTest \n",
    "    orientationsNames = datasetLoader.orientationsNames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6decc2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If working on RealWorld or HHAR with specified position/device, we remove one and use it as the test set and combine the others for training\n",
    "if(positionDevice != '' or dataSetName == 'UCI'):\n",
    "    if(dataSetName == \"RealWorld\"):\n",
    "        totalData = np.vstack((centralTrainData,centralTestData))\n",
    "        totalLabel = np.hstack((centralTrainLabel,centralTestLabel))\n",
    "        totalOrientation = np.hstack((np.hstack((clientOrientationTrain)), np.hstack((clientOrientationTest))))\n",
    "        totalIndex = list(range(totalOrientation.shape[0]))\n",
    "        testDataIndex = np.where(totalOrientation == orientationsNames.index(positionDevice))[0]\n",
    "        trainDataIndex = np.delete(totalIndex,testDataIndex)\n",
    "\n",
    "        centralTrainData = totalData[trainDataIndex]\n",
    "        centralTestData = totalData[testDataIndex]\n",
    "\n",
    "        centralTrainLabel = totalLabel[trainDataIndex]\n",
    "        centralTestLabel = totalLabel[testDataIndex]\n",
    "    elif(dataSetName == \"HHAR\"):\n",
    "        totalData = np.vstack((centralTrainData,centralTestData))\n",
    "        totalLabel = np.hstack((centralTrainLabel,centralTestLabel))\n",
    "        totalOrientation = np.hstack((np.hstack((clientOrientationTrain)), np.hstack((clientOrientationTest))))\n",
    "        totalIndex = list(range(totalOrientation.shape[0]))\n",
    "        # 0 is for nexus\n",
    "        testDataIndex = np.where(totalOrientation == orientationsNames.index(positionDevice))[0]\n",
    "        trainDataIndex = np.delete(totalIndex,testDataIndex)\n",
    "\n",
    "        centralTrainData = totalData[trainDataIndex]\n",
    "        centralTestData = totalData[testDataIndex]\n",
    "\n",
    "        centralTrainLabel = totalLabel[trainDataIndex]\n",
    "        centralTestLabel = totalLabel[testDataIndex]\n",
    "#         when using positions for evalaution, there is no test set , dev=test is the same\n",
    "    centralDevData = centralTestData\n",
    "    centralDevLabel = centralTestLabel\n",
    "else:\n",
    "#     using a 70 10 20 ratio\n",
    "    centralTrainData, centralDevData, centralTrainLabel, centralDevLabel = train_test_split(centralTrainData, centralTrainLabel, test_size=0.125, random_state=randomSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weight\n",
    "temp_weights = class_weight.compute_class_weight(class_weight = 'balanced',\n",
    "                                                 classes = np.unique(centralTrainLabel),\n",
    "                                                 y = centralTrainLabel.ravel())\n",
    "class_weights = {j : temp_weights[j] for j in range(len(temp_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f566db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot of labels\n",
    "centralTrainLabel = tf.one_hot(\n",
    "    centralTrainLabel,\n",
    "    activityCount,\n",
    "    on_value=None,\n",
    "    off_value=None,\n",
    "    axis=None,\n",
    "    dtype=None,\n",
    "    name=None\n",
    ")\n",
    "centralTestLabel = tf.one_hot(\n",
    "    centralTestLabel,\n",
    "    activityCount,\n",
    "    on_value=None,\n",
    "    off_value=None,\n",
    "    axis=None,\n",
    "    dtype=None,\n",
    "    name=None\n",
    ")\n",
    "centralDevLabel = tf.one_hot(\n",
    "    centralDevLabel,\n",
    "    activityCount,\n",
    "    on_value=None,\n",
    "    off_value=None,\n",
    "    axis=None,\n",
    "    dtype=None,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fdb0b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learningRate)\n",
    "\n",
    "if(architecture == \"HART\"):\n",
    "    model_classifier = model.HART(input_shape,activityCount)\n",
    "else:\n",
    "    model_classifier = model.mobileHART_XS(input_shape,activityCount)\n",
    "model_classifier.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e7aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = filepath+\"bestValcheckpoint.weights.h5\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath,\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "history = model_classifier.fit(\n",
    "    x=centralTrainData,\n",
    "    y=centralTrainLabel,\n",
    "    validation_data = (centralDevData,centralDevLabel),\n",
    "    batch_size=batch_size,\n",
    "    epochs=localEpoch,\n",
    "    verbose=showTrainVerbose,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "model_classifier.save_weights(filepath + 'bestTrain.weights.h5')\n",
    "model_classifier.load_weights(checkpoint_filepath)\n",
    "_, accuracy = model_classifier.evaluate(centralTestData, centralTestLabel)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "hkl.dump(history.history,filepath+'history.hkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fdb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayerIndexByName(model, layername):\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        if layer.name == layername:\n",
    "            return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b698e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(architecture == \"HART\"):\n",
    "    finalAccMHAIndex = getLayerIndexByName(model_classifier,\"AccMHA_\"+str(len(convKernels)-1))\n",
    "    finalGyroMHAIndex = getLayerIndexByName(model_classifier,\"GyroMHA_\"+str(len(convKernels)-1))\n",
    "    finalInputsIndex = getLayerIndexByName(model_classifier,\"normalizedInputs_\"+str(len(convKernels)-1))\n",
    "    totalLayer = len(model_classifier.layers)\n",
    "    classTokenIndex = totalLayer - 4\n",
    "else:\n",
    "    finalAccMHAIndex = getLayerIndexByName(model_classifier,\"AccMHA_1\")\n",
    "    finalGyroMHAIndex = getLayerIndexByName(model_classifier,\"GyroMHA_1\")\n",
    "    finalInputsIndex = getLayerIndexByName(model_classifier,\"normalizedInputs_1\")\n",
    "    classTokenIndex = getLayerIndexByName(model_classifier,\"GAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc1e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model_classifier.predict(centralTestData), axis=-1)\n",
    "\n",
    "y_test = np.argmax(centralTestLabel, axis=-1)\n",
    "weightVal_f1 = f1_score(y_test, y_pred,average='weighted' )\n",
    "microVal_f1 = f1_score(y_test, y_pred,average='micro')\n",
    "macroVal_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "\n",
    "modelStatistics = {\n",
    "\"Results on server model on ALL testsets\" : '',\n",
    "\"\\nTrain:\" : utils.roundNumber(np.max(history.history['accuracy'])),\n",
    "\"\\nValidation:\" : utils.roundNumber(np.max(history.history['val_accuracy'])),\n",
    "\"\\nTest weighted f1:\" : utils.roundNumber(weightVal_f1),\n",
    "\"\\nTest micro f1:\": utils.roundNumber(microVal_f1),\n",
    "\"\\nTest macro f1:\": utils.roundNumber(macroVal_f1),\n",
    "}    \n",
    "with open(filepath +'GlobalACC.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(modelStatistics.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b776b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xLabel = np.arange(0,2.58,0.02)\n",
    "idx = np.round(np.linspace(0, len(xLabel) - 1, 8)).astype(int)\n",
    "s = pd.Series(y_test)\n",
    "indices = [v.values[2] for k,v in s.groupby(s).groups.items()]\n",
    "segmentTime = [x for x in range(0,segment_size - frameLength + timeStep,timeStep)]\n",
    "inputModel = tf.keras.Model(inputs=model_classifier.inputs, outputs=model_classifier.layers[finalInputsIndex].output)\n",
    "\n",
    "for index, classLoc in enumerate(indices):\n",
    "    inputsToAttention = inputModel(np.expand_dims(centralTestData[classLoc],0))\n",
    "    _,attentionAccWeights = model_classifier.layers[finalAccMHAIndex](inputsToAttention, return_attention_scores=True)\n",
    "    _,attentionGyroWeights = model_classifier.layers[finalGyroMHAIndex](inputsToAttention, return_attention_scores=True)\n",
    "    if(tokenBased):\n",
    "        attentionScores = np.mean(attentionAccWeights[0],axis = 0)[0,1:]\n",
    "    else:\n",
    "         attentionScores = np.mean(attentionAccWeights[0],axis = 0)[0,:]\n",
    "    attentionScoresNorm = ((attentionScores - min(attentionScores))/(max(attentionScores) - min(attentionScores)) -1) * - 0.5\n",
    "    gs = gridspec.GridSpec(2,1)\n",
    "    fig = plt.figure()\n",
    "    plt.title(\"Attention Map for \"+ACTIVITY_LABEL[index]+\" \",size =16)    \n",
    "    plt.margins(x=0)\n",
    "    plt.tick_params(\n",
    "    axis='both',        \n",
    "    which='both',      \n",
    "    labelleft = False,\n",
    "    left = False,\n",
    "    bottom=False,      \n",
    "    top=False,         \n",
    "    labelbottom=False) \n",
    "\n",
    "    \n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    ax.margins(x=0)\n",
    "\n",
    "    ax.plot( centralTestData[classLoc][:,0], label = \"x-axis\")\n",
    "    ax.plot( centralTestData[classLoc][:,1], label = \"y-axis\")\n",
    "    ax.plot( centralTestData[classLoc][:,2], label = \"z-axis\")\n",
    "    for barIndex, starTime in enumerate(segmentTime):\n",
    "        ax.axvspan(starTime, starTime + frameLength, facecolor='black', alpha=float(attentionScoresNorm[barIndex]),zorder=4)\n",
    "        \n",
    "    ax.set_ylabel(r'Acc ($m/s^2$)', size =16)\n",
    "    ax.get_yaxis().set_label_coords(-0.1,0.5)\n",
    "    ax.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        labelbottom=False) \n",
    "    plt.legend(loc='upper right', framealpha = 0.7)\n",
    "\n",
    "    if(tokenBased):\n",
    "        attentionScores = np.mean(attentionGyroWeights[0],axis = 0)[0,1:]\n",
    "    else:\n",
    "        attentionScores = np.mean(attentionGyroWeights[0],axis = 0)[0,:]\n",
    "    attentionScoresNorm = ((attentionScores - min(attentionScores))/(max(attentionScores) - min(attentionScores)) -1) * - 0.5\n",
    "    \n",
    "    ax = fig.add_subplot(gs[1], sharex=ax)\n",
    "    ax.margins(x=0)\n",
    "\n",
    "    ax.plot( centralTestData[classLoc][:,3], label = \"x-axis\")\n",
    "    ax.plot( centralTestData[classLoc][:,4],label = \"y-axis\")\n",
    "    ax.plot( centralTestData[classLoc][:,5], label = \"z-axis\")\n",
    "    \n",
    "    for barIndex, starTime in enumerate(segmentTime):\n",
    "        ax.axvspan(starTime, starTime + frameLength, facecolor='black', alpha=float(attentionScoresNorm[barIndex]),zorder=99)\n",
    "\n",
    "    ax.set_ylabel(r'Gyro (rad/s)', size =16)\n",
    "    ax.get_yaxis().set_label_coords(-0.1,0.5)\n",
    "    plt.xticks([0,32,64,96,128])\n",
    "    fig.get_axes()[2].set_xticklabels([0,0.64,1.28,1.9, 2.56])\n",
    "    plt.xlabel(\"Time (s)\", size =16)\n",
    "    plt.margins(x=0)\n",
    "        \n",
    "\n",
    "    plt.savefig(attentionPath+ACTIVITY_LABEL[index]+\"MeanHeadAttention.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_learningCurve(history,localEpoch,filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2665c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLayer = len(model_classifier.layers)\n",
    "classTokenIndex = totalLayer - 4\n",
    "intermediateModel = utils.extract_intermediate_model_from_base_model(model_classifier,classTokenIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24658271",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = 30.0\n",
    "embeddings = intermediateModel.predict(centralTestData, batch_size=batch_size)\n",
    "del intermediateModel\n",
    "tsne_model = sklearn.manifold.TSNE(perplexity=perplexity, verbose=showTrainVerbose, random_state=randomSeed)\n",
    "tsne_projections = tsne_model.fit_transform(embeddings)\n",
    "labels_argmax = np.argmax(centralTestLabel, axis=-1)\n",
    "unique_labels = np.unique(labels_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if((dataSetName == 'RealWorld' or dataSetName == 'HHAR') and positionDevice == ''):\n",
    "    utils.projectTSNEWithPosition(dataSetName,architecture+\"_TSNE_Embeds\",filepath,ACTIVITY_LABEL,labels_argmax,orientationsNames,clientOrientationTest,tsne_projections,unique_labels)\n",
    "else:\n",
    "    utils.projectTSNE(architecture+\"_TSNE_Embeds\",filepath,ACTIVITY_LABEL,labels_argmax,tsne_projections,unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c72438",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(results, index = [i for i in ACTIVITY_LABEL],\n",
    "                  columns = [i for i in ACTIVITY_LABEL])\n",
    "plt.figure(figsize = (14,14))\n",
    "sns.set(font_scale=1.4) \n",
    "sns.heatmap(df_cm, annot=True,cmap=plt.cm.Blues,cbar=False)\n",
    "plt.ylabel('Prediction')\n",
    "plt.xlabel('Ground Truth')\n",
    "plt.savefig(filepath+'HeatMap.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_classifier)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(filepath +architecture+'.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d3398",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90251499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "har",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
