{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaa2bf3",
   "metadata": {},
   "source": [
    "# HAR模型 - PyTorch实现\n",
    "\n",
    "这个notebook实现了将TensorFlow版本的HART (Human Activity Recognition Transformer) 模型迁移到PyTorch的过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ddb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import shutil\n",
    "import gc\n",
    "import sys\n",
    "import sklearn.manifold\n",
    "import seaborn as sns\n",
    "import argparse\n",
    "import matplotlib.gridspec as gridspec\n",
    "import __main__ as main\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b807d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入自定义模块\n",
    "#import model_pytorch as model\n",
    "#import model_rnn as model\n",
    "#import model_hybrid as model\n",
    "import model_teacher as model\n",
    "import utils_torch as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def pick_free_gpu(threshold_mb=2000):\n",
    "    \"\"\"选择一个空闲内存大于阈值的GPU\"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"nvidia-smi\", \"--query-gpu=memory.free\", \"--format=csv,nounits,noheader\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    gpu_memory = [int(x) for x in result.stdout.strip().split('\\n')]\n",
    "    for idx, mem in enumerate(gpu_memory):\n",
    "        if mem > threshold_mb:\n",
    "            return str(idx)\n",
    "    return None\n",
    "\n",
    "# 选择GPU\n",
    "gpu_id = pick_free_gpu()\n",
    "if gpu_id is None:\n",
    "    print(\"没有找到空闲GPU，使用CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_id\n",
    "    device = torch.device(f\"cuda:{0}\")\n",
    "    print(f\"使用GPU:{gpu_id}\")'''\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 设置随机种子\n",
    "random_seed = 1\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a849d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interactive():\n",
    "    \"\"\"检查是否在交互式环境中运行\"\"\"\n",
    "    return not hasattr(main, '__file__')\n",
    "\n",
    "def get_layer_index_by_name(model, layername):\n",
    "    \"\"\"通过名称获取层的索引\"\"\"\n",
    "    for name, child in model.named_modules():\n",
    "        if name.endswith(layername):\n",
    "            return name\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc5397",
   "metadata": {},
   "source": [
    "## 设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76efdcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置默认超参数\n",
    "architecture = \"HART\"  # MobileHART, HART\n",
    "dataset_name = 'UCI'  # RealWorld, HHAR, UCI, SHL, MotionSense, COMBINED\n",
    "data_config = \"BALANCED\"  # BALANCED, UNBALANCED\n",
    "show_train_verbose = 1  # 显示训练详细信息: 0, 1\n",
    "segment_size = 128  # 输入窗口大小\n",
    "num_input_channels = 6  # 输入通道数\n",
    "learning_rate = 5e-3  # 学习率\n",
    "dropout_rate = 0.3  # 模型丢弃率\n",
    "local_epoch = 50  # 本地周期\n",
    "frame_length = 16  # 补丁大小\n",
    "time_step = 16  # 步长\n",
    "position_device = ''  # 位置/设备\n",
    "# ['chest','forearm','head','shin','thigh','upperarm','waist']\n",
    "# ['nexus4', 'lgwatch','s3', 's3mini','gear','samsungold']\n",
    "token_based = False  # 是否基于token\n",
    "\n",
    "# 模型超参数\n",
    "batch_size = 256\n",
    "projection_dim = 192\n",
    "filter_attention_head = 4\n",
    "# 调整HART的块数，添加或删除卷积核大小\n",
    "# 每个卷积核长度对应一个HART块\n",
    "conv_kernels = [3, 7, 15, 31, 31, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6187f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入形状和模型配置\n",
    "input_shape = (segment_size, num_input_channels)\n",
    "projection_half = projection_dim // 2\n",
    "projection_quarter = projection_dim // 4\n",
    "# 在初始化时打印这些值\n",
    "print(f\"projection_dim={projection_dim}, projection_half={projection_half}, projection_quarter={projection_quarter}\")\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Transformer层的大小\n",
    "\n",
    "R = projection_half // filter_attention_head\n",
    "assert R * filter_attention_head == projection_half\n",
    "\n",
    "segment_time = [x for x in range(0, segment_size - frame_length + time_step, time_step)]\n",
    "assert R * filter_attention_head == projection_half\n",
    "if position_device != '':\n",
    "    assert dataset_name == \"RealWorld\" or dataset_name == \"HHAR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212fb0c6",
   "metadata": {},
   "source": [
    "## 数据集和目录配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fbb94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'UCI':\n",
    "    ACTIVITY_LABEL = ['Walking', 'Upstair', 'Downstair', 'Sitting', 'Standing', 'Lying']\n",
    "elif dataset_name == \"RealWorld\":\n",
    "    ACTIVITY_LABEL = ['Downstairs', 'Upstairs', 'Jumping', 'Lying', 'Running', 'Sitting', 'Standing', 'Walking']\n",
    "elif dataset_name == \"MotionSense\":\n",
    "    ACTIVITY_LABEL = ['Downstairs', 'Upstairs', 'Sitting', 'Standing', 'Walking', 'Jogging']\n",
    "elif dataset_name == \"HHAR\":\n",
    "    ACTIVITY_LABEL = ['Sitting', 'Standing', 'Walking', 'Upstair', 'Downstairs', 'Biking']\n",
    "else:\n",
    "    # SHL\n",
    "    ACTIVITY_LABEL = ['Standing', 'Walking', 'Runing', 'Biking', 'Car', 'Bus', 'Train', 'Subway']\n",
    "\n",
    "activity_count = len(ACTIVITY_LABEL)\n",
    "\n",
    "# 定义主目录和文件路径\n",
    "main_dir = './'  # 设置主目录为当前目录\n",
    "\n",
    "architecture_type = str(architecture) + '_' + str(int(frame_length)) + 'frameLength_' + str(time_step) + 'TimeStep_' + str(projection_dim) + \"ProjectionSize_\" + str(learning_rate) + 'LR'\n",
    "if token_based:\n",
    "    architecture_type = architecture_type + \"_tokenBased\"\n",
    "    \n",
    "if position_device != '':\n",
    "    architecture_type = architecture_type + \"_PositionWise_\" + str(position_device)\n",
    "\n",
    "if local_epoch < 20:\n",
    "    architecture_type = \"Tests/\" + str(architecture_type)\n",
    "\n",
    "# 定义文件路径\n",
    "filepath = main_dir + 'HART_Results/' + architecture_type + '/' + dataset_name + '/'\n",
    "os.makedirs(filepath, exist_ok=True)\n",
    "\n",
    "attention_path = filepath + \"attentionImages/\"\n",
    "os.makedirs(attention_path, exist_ok=True)\n",
    "\n",
    "best_model_path = filepath + 'bestModels/'\n",
    "os.makedirs(best_model_path, exist_ok=True)\n",
    "\n",
    "current_model_path = filepath + 'currentModels/'\n",
    "os.makedirs(current_model_path, exist_ok=True)\n",
    "if device.type == \"mps\":\n",
    "    print(\"正在使用Mac的Metal性能着色器加速\")\n",
    "elif device.type == \"cuda\":\n",
    "    print(f\"可用GPU数量: {torch.cuda.device_count()}\")\n",
    "    print(f\"当前使用的GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"正在使用CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67b2818",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b4fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "if dataset_name == \"COMBINED\":\n",
    "    dataset_list = [\"UCI\", \"RealWorld\", \"HHAR\", \"MotionSense\", \"SHL_128\"]\n",
    "    ACTIVITY_LABEL = ['Walk', 'Upstair', 'Downstair', 'Sit', 'Stand', 'Lay', 'Jump', 'Run', 'Bike', 'Car', 'Bus', 'Train', 'Subway']\n",
    "    activity_count = len(ACTIVITY_LABEL)\n",
    "    UCI = [0, 1, 2, 3, 4, 5]\n",
    "    REALWORLD_CLIENT = [2, 1, 6, 5, 7, 3, 4, 0]\n",
    "    HHAR = [3, 4, 0, 1, 2, 8]\n",
    "    MotionSense = [2, 1, 3, 4, 0, 7]\n",
    "    SHL = [4, 0, 7, 8, 9, 10, 11, 12]\n",
    "    \n",
    "    central_train_data = []\n",
    "    central_train_label = []\n",
    "    central_test_data = []\n",
    "    central_test_label = []\n",
    "    for dataset_name_iter in dataset_list:\n",
    "        client_count = utils.return_client_by_dataset(dataset_name_iter) \n",
    "        loaded_dataset = utils.load_dataset_pytorch(dataset_name_iter, client_count, data_config, random_seed, os.path.join(main_dir, 'datasets/'))\n",
    "        central_train_data.append(loaded_dataset.central_train_data.cpu().numpy())\n",
    "        central_train_label.append(loaded_dataset.central_train_label.cpu().numpy())\n",
    "        central_test_data.append(loaded_dataset.central_test_data.cpu().numpy())\n",
    "        central_test_label.append(loaded_dataset.central_test_label.cpu().numpy())\n",
    "        print(dataset_name_iter + \" has class: \" + str(np.unique(central_train_label[-1])))\n",
    "        del loaded_dataset\n",
    "    \n",
    "    central_test_label_aligned = []\n",
    "    central_train_label_aligned = []\n",
    "    combined_aligned_data = central_test_data\n",
    "    for index, dataset_name_iter in enumerate(dataset_list):\n",
    "        if dataset_name_iter == 'UCI':\n",
    "            central_train_label_aligned.append(central_train_label[index])\n",
    "            central_test_label_aligned.append(central_test_label[index])\n",
    "        elif dataset_name_iter == 'RealWorld':\n",
    "            central_train_label_aligned.append(np.hstack([REALWORLD_CLIENT[label_index] for label_index in central_train_label[index]]))\n",
    "            central_test_label_aligned.append(np.hstack([REALWORLD_CLIENT[label_index] for label_index in central_test_label[index]]))\n",
    "        elif dataset_name_iter == 'HHAR':\n",
    "            central_train_label_aligned.append(np.hstack([HHAR[label_index] for label_index in central_train_label[index]]))\n",
    "            central_test_label_aligned.append(np.hstack([HHAR[label_index] for label_index in central_test_label[index]]))\n",
    "        elif dataset_name_iter == 'MotionSense':\n",
    "            central_train_label_aligned.append(np.hstack([MotionSense[label_index] for label_index in central_train_label[index]]))\n",
    "            central_test_label_aligned.append(np.hstack([MotionSense[label_index] for label_index in central_test_label[index]]))\n",
    "        else:\n",
    "            central_train_label_aligned.append(np.hstack([SHL[label_index] for label_index in central_train_label[index]]))\n",
    "            central_test_label_aligned.append(np.hstack([SHL[label_index] for label_index in central_test_label[index]]))\n",
    "    central_train_data = np.vstack((central_train_data))\n",
    "    central_test_data = np.vstack((central_test_data))\n",
    "    central_train_label = np.hstack((central_train_label_aligned))\n",
    "    central_test_label = np.hstack((central_test_label_aligned))\n",
    "else:\n",
    "    client_count = utils.return_client_by_dataset(dataset_name)\n",
    "    dataset_loader = utils.load_dataset_pytorch(dataset_name, client_count, data_config, random_seed, main_dir+ 'datasets/')\n",
    "    central_train_data = dataset_loader.central_train_data\n",
    "    central_train_label = dataset_loader.central_train_label\n",
    "    central_test_data = dataset_loader.central_test_data\n",
    "    central_test_label = dataset_loader.central_test_label\n",
    "    client_orientation_train = dataset_loader.client_orientation_train\n",
    "    client_orientation_test = dataset_loader.client_orientation_test\n",
    "    orientations_names = dataset_loader.orientations_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果在RealWorld或HHAR上使用指定位置/设备，我们移除一个并将其用作测试集，并将其他用于训练\n",
    "if position_device != '' or dataset_name == 'UCI':\n",
    "    if dataset_name == \"RealWorld\":\n",
    "        total_data = np.vstack((central_train_data, central_test_data))\n",
    "        total_label = np.hstack((central_train_label, central_test_label))\n",
    "        try:\n",
    "            total_orientation = np.hstack((np.hstack((client_orientation_train)), np.hstack((client_orientation_test))))\n",
    "        except:\n",
    "            total_orientation = np.hstack((np.hstack([x for x in client_orientation_train]), np.hstack([x for x in client_orientation_test])))\n",
    "        total_index = list(range(total_orientation.shape[0]))\n",
    "        test_data_index = np.where(total_orientation == orientations_names.index(position_device))[0]\n",
    "        train_data_index = np.delete(total_index, test_data_index)\n",
    "        \n",
    "        central_train_data = total_data[train_data_index]\n",
    "        central_test_data = total_data[test_data_index]\n",
    "        \n",
    "        central_train_label = total_label[train_data_index]\n",
    "        central_test_label = total_label[test_data_index]\n",
    "    elif dataset_name == \"HHAR\":\n",
    "        total_data = np.vstack((central_train_data, central_test_data))\n",
    "        total_label = np.hstack((central_train_label, central_test_label))\n",
    "        try:\n",
    "            total_orientation = np.hstack((np.hstack((client_orientation_train)), np.hstack((client_orientation_test))))\n",
    "        except:\n",
    "            total_orientation = np.hstack((np.hstack([x for x in client_orientation_train]), np.hstack([x for x in client_orientation_test])))\n",
    "        total_index = list(range(total_orientation.shape[0]))\n",
    "        # 0是nexus\n",
    "        test_data_index = np.where(total_orientation == orientations_names.index(position_device))[0]\n",
    "        train_data_index = np.delete(total_index, test_data_index)\n",
    "        \n",
    "        central_train_data = total_data[train_data_index]\n",
    "        central_test_data = total_data[test_data_index]\n",
    "        \n",
    "        central_train_label = total_label[train_data_index]\n",
    "        central_test_label = total_label[test_data_index]\n",
    "    # 使用位置进行评估时，没有测试集，dev=test是相同的\n",
    "    central_dev_data = central_test_data\n",
    "    central_dev_label = central_test_label\n",
    "else:\n",
    "    # 使用70 10 20比例\n",
    "    central_train_data, central_dev_data, central_train_label, central_dev_label = train_test_split(\n",
    "        central_train_data, central_train_label, test_size=0.125, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c583923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算类权重\n",
    "temp_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(central_train_label),\n",
    "    y=central_train_label.ravel()\n",
    ")\n",
    "class_weights = {j: temp_weights[j] for j in range(len(temp_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3368cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建PyTorch数据集和数据加载器\n",
    "# 创建特征和标签的张量\n",
    "train_features = torch.FloatTensor(central_train_data)\n",
    "train_labels = torch.LongTensor(central_train_label)\n",
    "dev_features = torch.FloatTensor(central_dev_data)\n",
    "dev_labels = torch.LongTensor(central_dev_label)\n",
    "test_features = torch.FloatTensor(central_test_data)\n",
    "test_labels = torch.LongTensor(central_test_label)\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = utils.HARDataset(train_features, train_labels)\n",
    "dev_dataset = utils.HARDataset(dev_features, dev_labels)\n",
    "test_dataset = utils.HARDataset(test_features, test_labels)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "dev_loader = torch.utils.data.DataLoader(\n",
    "    dev_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84be363",
   "metadata": {},
   "source": [
    "## 创建和训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "if architecture == \"HART\":\n",
    "    model_classifier = model.RNNAttentionHART(\n",
    "        input_shape=input_shape,\n",
    "        activity_count=activity_count,\n",
    "        projection_dim=projection_dim,\n",
    "        patch_size=frame_length,\n",
    "        time_step=time_step,\n",
    "        num_heads=3,\n",
    "        filter_attention_head=filter_attention_head,\n",
    "        conv_kernels=conv_kernels,\n",
    "        dropout_rate=dropout_rate,\n",
    "        use_tokens=token_based\n",
    "    ).to(device)\n",
    "else:\n",
    "    model_classifier = model.MobileHART_XS(\n",
    "        input_shape=input_shape,\n",
    "        activity_count=activity_count\n",
    "    ).to(device)\n",
    "\n",
    "# 转换类权重为PyTorch张量\n",
    "class_weights_tensor = torch.FloatTensor([class_weights[i] for i in range(activity_count)]).to(device)\n",
    "\n",
    "# 创建优化器和损失函数\n",
    "optimizer = torch.optim.Adam(\n",
    "    model_classifier.parameters(), \n",
    "    lr=learning_rate,\n",
    "    weight_decay=1e-4  # 添加适当的权重衰减\n",
    ")\n",
    "\n",
    "# 添加学习率调度器\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=local_epoch,  # 总周期数\n",
    "    eta_min=1e-6  # 最小学习率\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)\n",
    "\n",
    "# 模型摘要\n",
    "total_params = sum(p.numel() for p in model_classifier.parameters() if p.requires_grad)\n",
    "print(f\"模型总参数数量: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43530e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建检查点路径\n",
    "checkpoint_filepath = filepath + \"bestValcheckpoint.pt\"\n",
    "\n",
    "# 训练模型\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# 设置每个epoch的最大时间限制（秒）\n",
    "max_time_per_epoch = 60  # 60秒限制\n",
    "\n",
    "# 训练循环\n",
    "start_time = time.time()\n",
    "for epoch in range(local_epoch):\n",
    "    # 训练阶段\n",
    "    model_classifier.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    # 记录epoch开始时间\n",
    "    epoch_start_time = time.time()\n",
    "    time_limit_reached = False\n",
    "    \n",
    "    # 添加强制退出标志\n",
    "    force_break = False\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # 严格检查时间限制 - 每批次都检查\n",
    "        current_time = time.time()\n",
    "        if current_time - epoch_start_time > max_time_per_epoch:\n",
    "            print(f\"\\nEpoch {epoch+1} 已达到时间限制 ({max_time_per_epoch}秒)，提前结束！\")\n",
    "            print(f\"已处理 {i}/{len(train_loader)} 批次 ({i/len(train_loader)*100:.1f}%)\")\n",
    "            time_limit_reached = True\n",
    "            force_break = True\n",
    "            break\n",
    "            \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_classifier(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "\n",
    "        # 添加梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model_classifier.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 记录损失和准确率\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += targets.size(0)\n",
    "        train_correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # 在每10个批次后再次检查时间（更频繁的检查）\n",
    "        if i % 10 == 0 and i > 0:\n",
    "            if time.time() - epoch_start_time > max_time_per_epoch:\n",
    "                print(f\"\\nEpoch {epoch+1} 已达到时间限制 ({max_time_per_epoch}秒)，提前结束！\")\n",
    "                print(f\"已处理 {i}/{len(train_loader)} 批次 ({i/len(train_loader)*100:.1f}%)\")\n",
    "                time_limit_reached = True\n",
    "                force_break = True\n",
    "                break\n",
    "    \n",
    "    # 如果时间限制导致循环退出，输出警告并确保下一步操作继续\n",
    "    if force_break:\n",
    "        print(\"警告：由于时间限制强制退出训练循环\")\n",
    "    \n",
    "    # 只在处理了样本的情况下计算平均损失\n",
    "    if train_total > 0:\n",
    "        train_loss = train_loss / train_total\n",
    "        train_acc = train_correct / train_total\n",
    "    else:\n",
    "        train_loss = float('inf')\n",
    "        train_acc = 0.0\n",
    "    \n",
    "    # 验证阶段\n",
    "    model_classifier.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dev_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model_classifier(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # 记录损失和准确率\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += targets.size(0)\n",
    "            val_correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    # 记录历史\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_accuracy'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "    \n",
    "    # 计算本epoch花费的时间\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # 打印进度\n",
    "    if show_train_verbose == 1:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'Epoch {epoch+1}/{local_epoch} - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, '\n",
    "              f'LR: {current_lr:.6f}, Time: {epoch_time:.2f}s'\n",
    "              f'{\" (达到时间限制)\" if time_limit_reached else \"\"}')\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model_classifier.state_dict(), checkpoint_filepath)\n",
    "        print(f'保存最佳模型，验证准确率: {val_acc:.4f}')\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "            \n",
    "end_time = time.time() - start_time\n",
    "print(f\"训练时间: {end_time:.2f}秒\")\n",
    "\n",
    "# 保存当前模型\n",
    "torch.save(model_classifier.state_dict(), filepath + 'bestTrain.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280fa004",
   "metadata": {},
   "source": [
    "## 模型评估与分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d56730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型\n",
    "model_classifier.load_state_dict(torch.load(checkpoint_filepath))\n",
    "\n",
    "# 测试阶段\n",
    "model_classifier.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model_classifier(inputs)\n",
    "        \n",
    "        # 记录准确率\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += targets.size(0)\n",
    "        test_correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # 保存预测和真实标签\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# 计算测试准确率\n",
    "test_acc = test_correct / test_total\n",
    "print(f\"测试准确率: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505773dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存历史数据\n",
    "with open(filepath + 'history.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "# 计算F1分数\n",
    "weight_val_f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "micro_val_f1 = f1_score(all_targets, all_preds, average='micro')\n",
    "macro_val_f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "# 保存模型统计信息\n",
    "model_statistics = {\n",
    "    \"Results on server model on ALL testsets\": '',\n",
    "    \"\\nTrain:\": utils.round_number(max(history['train_accuracy'])),\n",
    "    \"\\nValidation:\": utils.round_number(max(history['val_accuracy'])),\n",
    "    \"\\nTest weighted f1:\": utils.round_number(weight_val_f1),\n",
    "    \"\\nTest micro f1:\": utils.round_number(micro_val_f1),\n",
    "    \"\\nTest macro f1:\": utils.round_number(macro_val_f1),\n",
    "}    \n",
    "with open(filepath + 'GlobalACC.csv', 'w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(model_statistics.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e37dd4",
   "metadata": {},
   "source": [
    "## 提取特征嵌入和t-SNE可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# 创建一个获取中间层输出的函数\n",
    "def get_intermediate_output(model, layer_name):\n",
    "    # 定义前向传递钩子\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output\n",
    "        return hook\n",
    "    \n",
    "    # 找到目标层并注册钩子\n",
    "    for name, module in model.named_modules():\n",
    "        if \"mlp_head.0\" in name:  # 获取mlp_head的第一层输入，即特征提取后的表示\n",
    "            module.register_forward_hook(get_activation(layer_name))\n",
    "            break\n",
    "    \n",
    "    return activation\n",
    "\n",
    "# 获取中间层的表示\n",
    "activation_dict = get_intermediate_output(model_classifier, \"features\")\n",
    "\n",
    "# 提取嵌入\n",
    "embeddings = []\n",
    "all_targets_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_classifier.eval()\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        # 前向传播，触发钩子\n",
    "        model_classifier(inputs)\n",
    "        # 获取激活值\n",
    "        if \"features\" in activation_dict:\n",
    "            feature_vector = activation_dict[\"features\"].cpu().numpy()\n",
    "            embeddings.append(feature_vector)\n",
    "            all_targets_list.extend(targets.numpy())\n",
    "\n",
    "# 将所有批次的嵌入堆叠在一起\n",
    "embeddings = np.vstack(embeddings)\n",
    "\n",
    "# t-SNE可视化\n",
    "perplexity = min(30.0, embeddings.shape[0] - 1)  # 确保perplexity小于样本数\n",
    "tsne_model = sklearn.manifold.TSNE(perplexity=perplexity, verbose=show_train_verbose, random_state=random_seed)\n",
    "tsne_projections = tsne_model.fit_transform(embeddings)\n",
    "\n",
    "# 准备标签\n",
    "labels_argmax = np.array(all_targets)\n",
    "unique_labels = np.unique(labels_argmax)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个获取中间层输出的函数，改进版本兼容不同模型类型\n",
    "def get_intermediate_output(model, layer_name):\n",
    "    # 定义前向传递钩子\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output\n",
    "        return hook\n",
    "    \n",
    "    # 首先尝试检查模型是否具有extract_features方法\n",
    "    if hasattr(model, 'extract_features'):\n",
    "        print(\"模型具有extract_features方法，将使用它来获取特征\")\n",
    "        \n",
    "        # 创建一个特殊钩子来捕获extract_features的输出\n",
    "        def extract_features_hook(inputs):\n",
    "            features = model.extract_features(inputs)\n",
    "            activation[layer_name] = features\n",
    "            return features\n",
    "        \n",
    "        # 保存原始方法的引用\n",
    "        original_extract_features = model.extract_features\n",
    "        \n",
    "        # 替换为我们的钩子版本\n",
    "        model.extract_features = extract_features_hook\n",
    "        \n",
    "        # 确保在使用后恢复原始方法\n",
    "        def restore_original():\n",
    "            model.extract_features = original_extract_features\n",
    "        \n",
    "        return activation, restore_original\n",
    "    \n",
    "    # 没有extract_features方法，尝试传统钩子方法\n",
    "    hook_registered = False\n",
    "    restore_func = lambda: None  # 默认不做任何事的恢复函数\n",
    "    \n",
    "    # 尝试注册到mlp_head.0（原始方法）\n",
    "    for name, module in model.named_modules():\n",
    "        if \"mlp_head.0\" in name:\n",
    "            module.register_forward_hook(get_activation(layer_name))\n",
    "            hook_registered = True\n",
    "            print(f\"钩子已注册到 {name}\")\n",
    "            break\n",
    "    \n",
    "    # 如果没有找到mlp_head.0，尝试其他常见特征提取点\n",
    "    if not hook_registered:\n",
    "        candidate_names = [\n",
    "            \"final_layer_norm\",  # 常见于Transformer类模型\n",
    "            \"mlp_head\",          # 检查整个mlp_head序列的第一层\n",
    "            \"transformer_layers\", # Transformer最后一层\n",
    "            \"classifier\"         # 分类层前可能有特征\n",
    "        ]\n",
    "        \n",
    "        for candidate in candidate_names:\n",
    "            if not hook_registered and hasattr(model, candidate):\n",
    "                if candidate == \"mlp_head\" and isinstance(getattr(model, candidate), nn.Sequential):\n",
    "                    # 获取第一个线性层\n",
    "                    for i, module in enumerate(getattr(model, candidate)):\n",
    "                        if isinstance(module, nn.Linear):\n",
    "                            module.register_forward_hook(get_activation(layer_name))\n",
    "                            hook_registered = True\n",
    "                            print(f\"钩子已注册到 mlp_head[{i}]\")\n",
    "                            break\n",
    "                else:\n",
    "                    # 直接注册到属性\n",
    "                    getattr(model, candidate).register_forward_hook(get_activation(layer_name))\n",
    "                    hook_registered = True\n",
    "                    print(f\"钩子已注册到 {candidate}\")\n",
    "                    break\n",
    "    \n",
    "    # 如果仍未找到适合的钩子点，给出警告\n",
    "    if not hook_registered:\n",
    "        print(\"警告：未找到合适的层注册钩子。特征提取可能失败。\")\n",
    "    \n",
    "    return activation, restore_func\n",
    "\n",
    "# 获取嵌入的增强版函数，兼容各种模型类型\n",
    "def get_embeddings(model, dataloader, device):\n",
    "    # 获取中间层的表示\n",
    "    activation_dict, restore_func = get_intermediate_output(model_classifier, \"features\")\n",
    "    \n",
    "    # 提取嵌入\n",
    "    embeddings = []\n",
    "    all_targets_list = []\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for inputs, targets in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                \n",
    "                # 检查是否有extract_features方法并且已被我们的钩子替换\n",
    "                if hasattr(model, 'extract_features') and model.extract_features.__name__ == 'extract_features_hook':\n",
    "                    # 直接调用extract_features，我们的钩子会捕获结果\n",
    "                    model.extract_features(inputs)\n",
    "                else:\n",
    "                    # 前向传播，触发常规钩子\n",
    "                    model(inputs)\n",
    "                \n",
    "                # 获取激活值\n",
    "                if \"features\" in activation_dict:\n",
    "                    feature_vector = activation_dict[\"features\"].cpu().numpy()\n",
    "                    embeddings.append(feature_vector)\n",
    "                    all_targets_list.extend(targets.numpy())\n",
    "                else:\n",
    "                    print(\"警告：此批次未捕获特征。\")\n",
    "        \n",
    "        # 恢复原始方法（如果已修改）\n",
    "        restore_func()\n",
    "        \n",
    "        if not embeddings:\n",
    "            raise ValueError(\"未能提取到任何特征嵌入\")\n",
    "            \n",
    "        # 将所有批次的嵌入堆叠在一起\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        all_targets = np.array(all_targets_list)\n",
    "        \n",
    "        print(f\"成功提取特征，形状: {embeddings.shape}\")\n",
    "        return embeddings, all_targets\n",
    "    \n",
    "    except Exception as e:\n",
    "        # 确保恢复原始方法\n",
    "        restore_func()\n",
    "        \n",
    "        # 尝试备用方法：检查模型是否有中间特征存储\n",
    "        print(f\"主要特征提取方法失败: {e}\")\n",
    "        print(\"尝试备用方法...\")\n",
    "        \n",
    "        if hasattr(model, 'intermediate_features'):\n",
    "            try:\n",
    "                backup_embeddings = []\n",
    "                backup_targets = []\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    for inputs, targets in dataloader:\n",
    "                        inputs = inputs.to(device)\n",
    "                        _ = model(inputs)  # 运行模型\n",
    "                        \n",
    "                        if model.intermediate_features is not None:\n",
    "                            features = model.intermediate_features.cpu().numpy()\n",
    "                            backup_embeddings.append(features)\n",
    "                            backup_targets.extend(targets.numpy())\n",
    "                \n",
    "                if backup_embeddings:\n",
    "                    embeddings = np.vstack(backup_embeddings)\n",
    "                    all_targets = np.array(backup_targets)\n",
    "                    print(f\"备用方法成功，提取特征形状: {embeddings.shape}\")\n",
    "                    return embeddings, all_targets\n",
    "            except Exception as backup_e:\n",
    "                print(f\"备用方法也失败了: {backup_e}\")\n",
    "        \n",
    "        # 如果所有方法都失败，重新抛出原始异常\n",
    "        raise ValueError(f\"所有特征提取方法均失败: {e}\")\n",
    "\n",
    "# 使用增强的特征提取函数获取嵌入\n",
    "try:\n",
    "    print(\"开始提取特征嵌入...\")\n",
    "    embeddings, all_targets_array = get_embeddings(model_classifier, test_loader, device)\n",
    "\n",
    "    # t-SNE可视化\n",
    "    print(\"开始t-SNE降维...\")\n",
    "    perplexity = min(30.0, embeddings.shape[0] - 1)  # 确保perplexity小于样本数\n",
    "    tsne_model = sklearn.manifold.TSNE(perplexity=perplexity, verbose=show_train_verbose, random_state=random_seed)\n",
    "    tsne_projections = tsne_model.fit_transform(embeddings)\n",
    "\n",
    "    # 准备标签\n",
    "    labels_argmax = all_targets_array\n",
    "    unique_labels = np.unique(labels_argmax)\n",
    "\n",
    "    print(f\"t-SNE降维完成，投影形状: {tsne_projections.shape}\")\n",
    "    print(f\"识别到的活动类别: {len(unique_labels)}\")\n",
    "\n",
    "    # 绘制t-SNE图\n",
    "    if (dataset_name == 'RealWorld' or dataset_name == 'HHAR') and position_device == '':\n",
    "        utils.project_tsne_with_position(dataset_name, architecture + \"_TSNE_Embeds\", filepath, ACTIVITY_LABEL,\n",
    "                                       labels_argmax, orientations_names, client_orientation_test,\n",
    "                                       tsne_projections, unique_labels)\n",
    "    else:\n",
    "        utils.project_tsne(architecture + \"_TSNE_Embeds\", filepath, ACTIVITY_LABEL,\n",
    "                         labels_argmax, tsne_projections, unique_labels)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"t-SNE可视化过程失败: {e}\")\n",
    "    \n",
    "    # 提供简单的备用可视化函数\n",
    "    def simple_tsne_plot(save_path):\n",
    "        \"\"\"简单的特征可视化函数，不依赖于特征提取\"\"\"\n",
    "        print(\"使用简单备用可视化...\")\n",
    "        \n",
    "        # 收集最后线性层之前的特征\n",
    "        backup_features = []\n",
    "        backup_labels = []\n",
    "        \n",
    "        # 尝试获取分类器前的特征\n",
    "        with torch.no_grad():\n",
    "            model_classifier.eval()\n",
    "            \n",
    "            # 找到最后一个线性层之前的层\n",
    "            pre_final_layer = None\n",
    "            for name, module in model_classifier.named_modules():\n",
    "                if isinstance(module, nn.Linear) and 'classifier' in name:\n",
    "                    # 找到了分类器，现在找它的输入\n",
    "                    for parent_name, parent_module in model_classifier.named_modules():\n",
    "                        if parent_name and parent_name in name and parent_name != name:\n",
    "                            pre_final_layer = parent_module\n",
    "                            break\n",
    "                    break\n",
    "            \n",
    "            if pre_final_layer is None:\n",
    "                print(\"警告：无法识别预分类层，将使用随机数据进行示例可视化\")\n",
    "                # 生成随机数据进行演示\n",
    "                random_features = np.random.rand(100, 2)\n",
    "                random_labels = np.random.randint(0, len(ACTIVITY_LABEL), 100)\n",
    "                \n",
    "                plt.figure(figsize=(10, 10))\n",
    "                for i in range(len(ACTIVITY_LABEL)):\n",
    "                    mask = random_labels == i\n",
    "                    if np.any(mask):\n",
    "                        plt.scatter(random_features[mask, 0], random_features[mask, 1], \n",
    "                                   label=ACTIVITY_LABEL[i])\n",
    "                \n",
    "                plt.legend()\n",
    "                plt.title(\"示例t-SNE可视化（使用随机数据）\")\n",
    "                plt.savefig(save_path, dpi=300)\n",
    "                plt.close()\n",
    "                return\n",
    "            \n",
    "            # 使用钩子捕获特征\n",
    "            activation = {}\n",
    "            def hook(module, input, output):\n",
    "                activation['features'] = input[0]\n",
    "            \n",
    "            hook_handle = pre_final_layer.register_forward_hook(hook)\n",
    "            \n",
    "            for inputs, targets in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                _ = model_classifier(inputs)\n",
    "                \n",
    "                if 'features' in activation:\n",
    "                    features = activation['features'].cpu().numpy()\n",
    "                    backup_features.append(features)\n",
    "                    backup_labels.extend(targets.numpy())\n",
    "            \n",
    "            hook_handle.remove()\n",
    "            \n",
    "            if backup_features:\n",
    "                # 创建t-SNE可视化\n",
    "                backup_features = np.vstack(backup_features)\n",
    "                backup_labels = np.array(backup_labels)\n",
    "                \n",
    "                # t-SNE降维\n",
    "                perplexity = min(30.0, backup_features.shape[0] - 1)\n",
    "                backup_tsne = sklearn.manifold.TSNE(\n",
    "                    perplexity=perplexity, \n",
    "                    random_state=random_seed\n",
    "                ).fit_transform(backup_features)\n",
    "                \n",
    "                # 创建可视化\n",
    "                plt.figure(figsize=(16, 16))\n",
    "                for i in range(len(ACTIVITY_LABEL)):\n",
    "                    mask = backup_labels == i\n",
    "                    if np.any(mask):\n",
    "                        plt.scatter(\n",
    "                            backup_tsne[mask, 0], \n",
    "                            backup_tsne[mask, 1],\n",
    "                            label=ACTIVITY_LABEL[i]\n",
    "                        )\n",
    "                \n",
    "                plt.legend(fontsize=12)\n",
    "                plt.title('t-SNE特征可视化（备用方法）', fontsize=16)\n",
    "                plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                print(f\"备用t-SNE图已保存至: {save_path}\")\n",
    "    \n",
    "    # 如果主要可视化失败，使用简单备用方法\n",
    "    simple_tsne_plot(filepath + architecture + \"_TSNE_Embeds_backup.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a44fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# 绘制t-SNE图\n",
    "if (dataset_name == 'RealWorld' or dataset_name == 'HHAR') and position_device == '':\n",
    "    utils.project_tsne_with_position(dataset_name, architecture + \"_TSNE_Embeds\", filepath, ACTIVITY_LABEL,\n",
    "                                   labels_argmax, orientations_names, client_orientation_test,\n",
    "                                   tsne_projections, unique_labels)\n",
    "else:\n",
    "    utils.project_tsne(architecture + \"_TSNE_Embeds\", filepath, ACTIVITY_LABEL,\n",
    "                     labels_argmax, tsne_projections, unique_labels)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a1b2c6",
   "metadata": {},
   "source": [
    "## 绘制混淆矩阵和注意力可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制混淆矩阵\n",
    "results = confusion_matrix(all_targets, all_preds)\n",
    "df_cm = pd.DataFrame(results, index=[i for i in ACTIVITY_LABEL],\n",
    "                  columns=[i for i in ACTIVITY_LABEL])\n",
    "plt.figure(figsize=(14, 14))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, cbar=False)\n",
    "plt.ylabel('预测')\n",
    "plt.xlabel('真实')\n",
    "plt.savefig(filepath + 'HeatMap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取模型中的关键层\n",
    "if architecture == \"HART\":\n",
    "    final_acc_mha_name = get_layer_index_by_name(model_classifier, f\"AccMHA_{len(conv_kernels)-1}\")\n",
    "    final_gyro_mha_name = get_layer_index_by_name(model_classifier, f\"GyroMHA_{len(conv_kernels)-1}\")\n",
    "    final_inputs_name = get_layer_index_by_name(model_classifier, f\"normalizedInputs_{len(conv_kernels)-1}\")\n",
    "    \n",
    "    # 创建hook函数获取中间输出\n",
    "    intermediate_outputs = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            intermediate_outputs[name] = output\n",
    "        return hook\n",
    "    \n",
    "    # 注册钩子\n",
    "    for name, module in model_classifier.named_modules():\n",
    "        if name == final_inputs_name:\n",
    "            module.register_forward_hook(get_activation(final_inputs_name))\n",
    "            \n",
    "    # 选择一些样本用于可视化\n",
    "    indices = []\n",
    "    for label in range(activity_count):\n",
    "        label_indices = np.where(np.array(all_targets) == label)[0]\n",
    "        if len(label_indices) > 0:\n",
    "            indices.append(label_indices[2] if len(label_indices) > 2 else label_indices[0])\n",
    "    \n",
    "    segment_time = [x for x in range(0, segment_size - frame_length + time_step, time_step)]\n",
    "    \n",
    "    # 可视化注意力\n",
    "    for index, class_loc in enumerate(indices):\n",
    "        # 获取样本\n",
    "        sample = test_features[class_loc].unsqueeze(0).to(device)\n",
    "        \n",
    "        # 清空中间输出\n",
    "        intermediate_outputs.clear()\n",
    "        \n",
    "        # 前向传播\n",
    "        with torch.no_grad():\n",
    "            model_classifier(sample)\n",
    "            \n",
    "        # 注意：这里我们模拟注意力可视化\n",
    "        # 实际上需要从模型中提取注意力权重\n",
    "        # 由于PyTorch版本的模型结构不同，这里仅为示例\n",
    "        \n",
    "        # 生成伪注意力分数\n",
    "        attention_scores = np.random.rand(len(segment_time))\n",
    "        attention_scores_norm = ((attention_scores - min(attention_scores))/(max(attention_scores) - min(attention_scores)) -1) * - 0.5\n",
    "        \n",
    "        # 绘制第一组图（加速度计数据）\n",
    "        gs = gridspec.GridSpec(2, 1)\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        plt.title(f\"Attention Map for {ACTIVITY_LABEL[index]}\", size=16)\n",
    "        plt.margins(x=0)\n",
    "        plt.tick_params(\n",
    "        axis='both',\n",
    "        which='both',\n",
    "        labelleft=False,\n",
    "        left=False,\n",
    "        bottom=False,\n",
    "        top=False,\n",
    "        labelbottom=False)\n",
    "        \n",
    "        # 加速度计数据\n",
    "        ax = fig.add_subplot(gs[0])\n",
    "        ax.margins(x=0)\n",
    "        \n",
    "        sample_np = sample.cpu().numpy()[0]\n",
    "        ax.plot(sample_np[:, 0], label=\"x-axis\")\n",
    "        ax.plot(sample_np[:, 1], label=\"y-axis\")\n",
    "        ax.plot(sample_np[:, 2], label=\"z-axis\")\n",
    "        \n",
    "        for bar_index, start_time in enumerate(segment_time):\n",
    "            ax.axvspan(start_time, start_time + frame_length, facecolor='black', alpha=float(attention_scores_norm[bar_index]), zorder=4)\n",
    "        \n",
    "        ax.set_ylabel(r'Acc ($m/s^2$)', size=16)\n",
    "        ax.get_yaxis().set_label_coords(-0.1, 0.5)\n",
    "        ax.tick_params(axis='x', labelbottom=False)\n",
    "        plt.legend(loc='upper right', framealpha=0.7)\n",
    "        \n",
    "        # 生成第二组伪注意力分数\n",
    "        attention_scores = np.random.rand(len(segment_time))\n",
    "        attention_scores_norm = ((attention_scores - min(attention_scores))/(max(attention_scores) - min(attention_scores)) -1) * - 0.5\n",
    "        \n",
    "        # 陀螺仪数据\n",
    "        ax = fig.add_subplot(gs[1], sharex=ax)\n",
    "        ax.margins(x=0)\n",
    "        \n",
    "        ax.plot(sample_np[:, 3], label=\"x-axis\")\n",
    "        ax.plot(sample_np[:, 4], label=\"y-axis\")\n",
    "        ax.plot(sample_np[:, 5], label=\"z-axis\")\n",
    "        \n",
    "        for bar_index, start_time in enumerate(segment_time):\n",
    "            ax.axvspan(start_time, start_time + frame_length, facecolor='black', alpha=float(attention_scores_norm[bar_index]), zorder=99)\n",
    "        \n",
    "        ax.set_ylabel(r'Gyro (rad/s)', size=16)\n",
    "        ax.get_yaxis().set_label_coords(-0.1, 0.5)\n",
    "        plt.xticks([0, 32, 64, 96, 128])\n",
    "        if len(fig.get_axes()) > 1:\n",
    "            fig.get_axes()[1].set_xticklabels([0, 0.64, 1.28, 1.9, 2.56])\n",
    "        plt.xlabel(\"Time (s)\", size=16)\n",
    "        plt.margins(x=0)\n",
    "        \n",
    "        plt.savefig(attention_path + ACTIVITY_LABEL[index] + \"MeanHeadAttention.png\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a82da7a",
   "metadata": {},
   "source": [
    "## 学习曲线和模型导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制学习曲线\n",
    "utils.plot_learning_curve(history, local_epoch, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55295ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出ONNX模型\n",
    "# TODO:模型导出有bug\n",
    "'''dummy_input = torch.randn(1, segment_size, num_input_channels, device=device)\n",
    "torch.onnx.export(\n",
    "    model_classifier,\n",
    "    dummy_input,\n",
    "    filepath + architecture + '.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(\"模型已导出为ONNX格式\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示模型性能统计\n",
    "print(f\"训练准确率: {max(history['train_accuracy']) * 100:.2f}%\")\n",
    "print(f\"验证准确率: {max(history['val_accuracy']) * 100:.2f}%\")\n",
    "print(f\"测试准确率: {test_acc * 100:.2f}%\")\n",
    "print(f\"测试加权F1分数: {weight_val_f1:.4f}\")\n",
    "print(f\"测试微平均F1分数: {micro_val_f1:.4f}\")\n",
    "print(f\"测试宏平均F1分数: {macro_val_f1:.4f}\")\n",
    "print(\"训练完成!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
